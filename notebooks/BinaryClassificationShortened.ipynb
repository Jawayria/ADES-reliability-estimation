{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61db74da29e860b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:27.496697Z",
     "start_time": "2025-02-05T11:09:27.484924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'datamanip' (<_frozen_importlib_external.NamespaceLoader object at 0x107a42c90>)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import datamanip\n",
    "importlib.reload(datamanip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8602fbdefee2bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:27.506597Z",
     "start_time": "2025-02-05T11:09:27.501967Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from filepath import *\n",
    "from datamanip.plots import generate_matrix, generate_metrics\n",
    "from models.GAT import GAT#, GCN, SimpleMPNN\n",
    "from train_eval.train import train\n",
    "from train_eval.evaluate import evaluate\n",
    "from datamanip.datasetmanip.three_five_dataset import ThreeFiveDataset\n",
    "from datamanip.datasetmanip.dataset_util import split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4367eaefa0afab",
   "metadata": {},
   "source": [
    "# Model Selection by number of 9's\n",
    "### 1. Match 1-1: 0 vs. 7\n",
    "### 2. Match 2-1: 0/1 vs. 2/3\n",
    "### 3. Match 2-2: 4/5 vs. 6/7\n",
    "### 4. Match 3-1: 0 vs. 1\n",
    "### 5. Match 3-2: 2 vs. 3\n",
    "### 6. Match 3-3: 4 vs. 5\n",
    "### 7. Match 3-4: 6 vs. 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f58b512338cbca1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:27.535460Z",
     "start_time": "2025-02-05T11:09:27.533451Z"
    }
   },
   "outputs": [],
   "source": [
    "match = \"3-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7d21d4096e7504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:27.541188Z",
     "start_time": "2025-02-05T11:09:27.538131Z"
    }
   },
   "outputs": [],
   "source": [
    "if match == \"1-1\":\n",
    "    NUM_EPOCHS = 150\n",
    "    DROPOUT_RATE = 0.01\n",
    "    LEARNING_RATE = 0.0005\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 30\n",
    "    HIDDEN_DIM = 64\n",
    "elif match == \"2-1\":\n",
    "    NUM_EPOCHS = 100\n",
    "    DROPOUT_RATE = 0.3\n",
    "    LEARNING_RATE = 0.0005\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 15\n",
    "    HIDDEN_DIM = 16\n",
    "elif match == \"2-2\":\n",
    "    NUM_EPOCHS = 150\n",
    "    DROPOUT_RATE = 0.3\n",
    "    LEARNING_RATE = 0.0005\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 15\n",
    "    HIDDEN_DIM = 28\n",
    "elif match == \"3-1\":\n",
    "    NUM_EPOCHS = 150\n",
    "    DROPOUT_RATE = 0.3\n",
    "    LEARNING_RATE = 0.0005\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 15\n",
    "    HIDDEN_DIM = 82\n",
    "\n",
    "elif match == \"3-2\":\n",
    "    NUM_EPOCHS = 200\n",
    "    DROPOUT_RATE = 0.3\n",
    "    LEARNING_RATE = 0.0001\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 30\n",
    "    HIDDEN_DIM = 128\n",
    "elif match == \"3-3\":\n",
    "    NUM_EPOCHS = 200\n",
    "    DROPOUT_RATE = 0.3\n",
    "    LEARNING_RATE = 0.0005\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 30\n",
    "    HIDDEN_DIM = 64\n",
    "elif match == \"3-4\":\n",
    "    NUM_EPOCHS = 200\n",
    "    DROPOUT_RATE = 0.3\n",
    "    LEARNING_RATE = 0.0005\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 20\n",
    "    HIDDEN_DIM = 32\n",
    "else:\n",
    "    NUM_EPOCHS = 100\n",
    "    DROPOUT_RATE = 0.2\n",
    "    LEARNING_RATE = 0.0007\n",
    "    NODE_FEATURES = 10\n",
    "    PATIENCE = 15\n",
    "    HIDDEN_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d7cd5f-f1d3-4844-a218-365a41c5c127",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:27.625111Z",
     "start_time": "2025-02-05T11:09:27.548684Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create list of Data objects, each containing the node features, edge indices, and target values\n",
    "data_list = ThreeFiveDataset(root=dataset_path, match=match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd3e54c6af9ac8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:28.138486Z",
     "start_time": "2025-02-05T11:09:27.633421Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = split_dataset(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45354d30-7347-451e-9445-79761c7ffe69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:28.151530Z",
     "start_time": "2025-02-05T11:09:28.145228Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(input_dim=NODE_FEATURES, hidden_dim=HIDDEN_DIM, output_dim=2, dropout_rate=DROPOUT_RATE).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db2e7a3e-1e4d-4f99-af36-cea56f7dab65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:09:28.160182Z",
     "start_time": "2025-02-05T11:09:28.157602Z"
    }
   },
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"patience\": PATIENCE,\n",
    "    \"device\": device,\n",
    "    \"criterion\": criterion,\n",
    "    \"optimizer\": optimizer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b8ebbd-6e46-407b-8c07-df0de71665f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:10:36.110723Z",
     "start_time": "2025-02-05T11:09:28.259291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.6009\n",
      "Epoch 1/200, Validation Loss: 0.5946\n",
      "Best model updated based on validation loss.\n",
      "Epoch 2/200, Train Loss: 0.5480\n",
      "Epoch 2/200, Validation Loss: 0.5569\n",
      "Best model updated based on validation loss.\n",
      "Epoch 3/200, Train Loss: 0.5140\n",
      "Epoch 3/200, Validation Loss: 0.4815\n",
      "Best model updated based on validation loss.\n",
      "Epoch 4/200, Train Loss: 0.5016\n",
      "Epoch 4/200, Validation Loss: 0.4894\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 5/200, Train Loss: 0.4948\n",
      "Epoch 5/200, Validation Loss: 0.4690\n",
      "Best model updated based on validation loss.\n",
      "Epoch 6/200, Train Loss: 0.4864\n",
      "Epoch 6/200, Validation Loss: 0.4567\n",
      "Best model updated based on validation loss.\n",
      "Epoch 7/200, Train Loss: 0.4844\n",
      "Epoch 7/200, Validation Loss: 0.4585\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 8/200, Train Loss: 0.4803\n",
      "Epoch 8/200, Validation Loss: 0.6270\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 9/200, Train Loss: 0.4754\n",
      "Epoch 9/200, Validation Loss: 0.4828\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 10/200, Train Loss: 0.4771\n",
      "Epoch 10/200, Validation Loss: 0.4422\n",
      "Best model updated based on validation loss.\n",
      "Epoch 11/200, Train Loss: 0.4689\n",
      "Epoch 11/200, Validation Loss: 0.4701\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 12/200, Train Loss: 0.4724\n",
      "Epoch 12/200, Validation Loss: 0.4454\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 13/200, Train Loss: 0.4667\n",
      "Epoch 13/200, Validation Loss: 0.4486\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 14/200, Train Loss: 0.4672\n",
      "Epoch 14/200, Validation Loss: 0.4564\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 15/200, Train Loss: 0.4581\n",
      "Epoch 15/200, Validation Loss: 0.4235\n",
      "Best model updated based on validation loss.\n",
      "Epoch 16/200, Train Loss: 0.4537\n",
      "Epoch 16/200, Validation Loss: 0.5465\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 17/200, Train Loss: 0.4543\n",
      "Epoch 17/200, Validation Loss: 0.4272\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 18/200, Train Loss: 0.4500\n",
      "Epoch 18/200, Validation Loss: 0.4202\n",
      "Best model updated based on validation loss.\n",
      "Epoch 19/200, Train Loss: 0.4444\n",
      "Epoch 19/200, Validation Loss: 0.4064\n",
      "Best model updated based on validation loss.\n",
      "Epoch 20/200, Train Loss: 0.4398\n",
      "Epoch 20/200, Validation Loss: 0.4292\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 21/200, Train Loss: 0.4388\n",
      "Epoch 21/200, Validation Loss: 0.5166\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 22/200, Train Loss: 0.4364\n",
      "Epoch 22/200, Validation Loss: 0.4381\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 23/200, Train Loss: 0.4340\n",
      "Epoch 23/200, Validation Loss: 0.3941\n",
      "Best model updated based on validation loss.\n",
      "Epoch 24/200, Train Loss: 0.4272\n",
      "Epoch 24/200, Validation Loss: 0.4553\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 25/200, Train Loss: 0.4279\n",
      "Epoch 25/200, Validation Loss: 0.4084\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 26/200, Train Loss: 0.4216\n",
      "Epoch 26/200, Validation Loss: 0.4560\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 27/200, Train Loss: 0.4140\n",
      "Epoch 27/200, Validation Loss: 0.3969\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 28/200, Train Loss: 0.4131\n",
      "Epoch 28/200, Validation Loss: 0.4024\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 29/200, Train Loss: 0.4168\n",
      "Epoch 29/200, Validation Loss: 0.4106\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 30/200, Train Loss: 0.4174\n",
      "Epoch 30/200, Validation Loss: 0.4140\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 31/200, Train Loss: 0.4111\n",
      "Epoch 31/200, Validation Loss: 0.4051\n",
      "No improvement in validation loss for 8 epoch(s).\n",
      "Epoch 32/200, Train Loss: 0.4094\n",
      "Epoch 32/200, Validation Loss: 0.5560\n",
      "No improvement in validation loss for 9 epoch(s).\n",
      "Epoch 33/200, Train Loss: 0.4062\n",
      "Epoch 33/200, Validation Loss: 0.3624\n",
      "Best model updated based on validation loss.\n",
      "Epoch 34/200, Train Loss: 0.4051\n",
      "Epoch 34/200, Validation Loss: 0.3565\n",
      "Best model updated based on validation loss.\n",
      "Epoch 35/200, Train Loss: 0.4043\n",
      "Epoch 35/200, Validation Loss: 0.3562\n",
      "Best model updated based on validation loss.\n",
      "Epoch 36/200, Train Loss: 0.4049\n",
      "Epoch 36/200, Validation Loss: 0.4444\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 37/200, Train Loss: 0.4030\n",
      "Epoch 37/200, Validation Loss: 0.4072\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 38/200, Train Loss: 0.3968\n",
      "Epoch 38/200, Validation Loss: 0.7132\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 39/200, Train Loss: 0.4012\n",
      "Epoch 39/200, Validation Loss: 0.3951\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 40/200, Train Loss: 0.3994\n",
      "Epoch 40/200, Validation Loss: 0.3866\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 41/200, Train Loss: 0.3998\n",
      "Epoch 41/200, Validation Loss: 0.4133\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 42/200, Train Loss: 0.4032\n",
      "Epoch 42/200, Validation Loss: 0.3970\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 43/200, Train Loss: 0.3975\n",
      "Epoch 43/200, Validation Loss: 0.5682\n",
      "No improvement in validation loss for 8 epoch(s).\n",
      "Epoch 44/200, Train Loss: 0.3939\n",
      "Epoch 44/200, Validation Loss: 0.3716\n",
      "No improvement in validation loss for 9 epoch(s).\n",
      "Epoch 45/200, Train Loss: 0.3949\n",
      "Epoch 45/200, Validation Loss: 0.3684\n",
      "No improvement in validation loss for 10 epoch(s).\n",
      "Epoch 46/200, Train Loss: 0.4003\n",
      "Epoch 46/200, Validation Loss: 0.5785\n",
      "No improvement in validation loss for 11 epoch(s).\n",
      "Epoch 47/200, Train Loss: 0.3950\n",
      "Epoch 47/200, Validation Loss: 0.3834\n",
      "No improvement in validation loss for 12 epoch(s).\n",
      "Epoch 48/200, Train Loss: 0.3874\n",
      "Epoch 48/200, Validation Loss: 0.3466\n",
      "Best model updated based on validation loss.\n",
      "Epoch 49/200, Train Loss: 0.3915\n",
      "Epoch 49/200, Validation Loss: 0.4682\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 50/200, Train Loss: 0.3896\n",
      "Epoch 50/200, Validation Loss: 0.3441\n",
      "Best model updated based on validation loss.\n",
      "Epoch 51/200, Train Loss: 0.3872\n",
      "Epoch 51/200, Validation Loss: 0.3731\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 52/200, Train Loss: 0.3882\n",
      "Epoch 52/200, Validation Loss: 0.4988\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 53/200, Train Loss: 0.3859\n",
      "Epoch 53/200, Validation Loss: 0.4305\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 54/200, Train Loss: 0.3934\n",
      "Epoch 54/200, Validation Loss: 0.3321\n",
      "Best model updated based on validation loss.\n",
      "Epoch 55/200, Train Loss: 0.3915\n",
      "Epoch 55/200, Validation Loss: 0.3326\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 56/200, Train Loss: 0.3857\n",
      "Epoch 56/200, Validation Loss: 0.5057\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 57/200, Train Loss: 0.3880\n",
      "Epoch 57/200, Validation Loss: 0.3571\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 58/200, Train Loss: 0.3811\n",
      "Epoch 58/200, Validation Loss: 0.3988\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 59/200, Train Loss: 0.3839\n",
      "Epoch 59/200, Validation Loss: 0.3323\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 60/200, Train Loss: 0.3871\n",
      "Epoch 60/200, Validation Loss: 0.3277\n",
      "Best model updated based on validation loss.\n",
      "Epoch 61/200, Train Loss: 0.3791\n",
      "Epoch 61/200, Validation Loss: 0.3747\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 62/200, Train Loss: 0.3805\n",
      "Epoch 62/200, Validation Loss: 0.3271\n",
      "Best model updated based on validation loss.\n",
      "Epoch 63/200, Train Loss: 0.3768\n",
      "Epoch 63/200, Validation Loss: 0.3472\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 64/200, Train Loss: 0.3773\n",
      "Epoch 64/200, Validation Loss: 0.3255\n",
      "Best model updated based on validation loss.\n",
      "Epoch 65/200, Train Loss: 0.3806\n",
      "Epoch 65/200, Validation Loss: 0.3440\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 66/200, Train Loss: 0.3732\n",
      "Epoch 66/200, Validation Loss: 0.3740\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 67/200, Train Loss: 0.3785\n",
      "Epoch 67/200, Validation Loss: 0.3540\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 68/200, Train Loss: 0.3780\n",
      "Epoch 68/200, Validation Loss: 0.3368\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 69/200, Train Loss: 0.3811\n",
      "Epoch 69/200, Validation Loss: 0.3832\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 70/200, Train Loss: 0.3801\n",
      "Epoch 70/200, Validation Loss: 0.3211\n",
      "Best model updated based on validation loss.\n",
      "Epoch 71/200, Train Loss: 0.3794\n",
      "Epoch 71/200, Validation Loss: 0.3476\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 72/200, Train Loss: 0.3749\n",
      "Epoch 72/200, Validation Loss: 0.3222\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 73/200, Train Loss: 0.3743\n",
      "Epoch 73/200, Validation Loss: 0.3228\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 74/200, Train Loss: 0.3704\n",
      "Epoch 74/200, Validation Loss: 0.3617\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 75/200, Train Loss: 0.3710\n",
      "Epoch 75/200, Validation Loss: 0.3402\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 76/200, Train Loss: 0.3776\n",
      "Epoch 76/200, Validation Loss: 0.3193\n",
      "Best model updated based on validation loss.\n",
      "Epoch 77/200, Train Loss: 0.3693\n",
      "Epoch 77/200, Validation Loss: 0.3295\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 78/200, Train Loss: 0.3729\n",
      "Epoch 78/200, Validation Loss: 0.3151\n",
      "Best model updated based on validation loss.\n",
      "Epoch 79/200, Train Loss: 0.3804\n",
      "Epoch 79/200, Validation Loss: 0.3913\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 80/200, Train Loss: 0.3726\n",
      "Epoch 80/200, Validation Loss: 0.4308\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 81/200, Train Loss: 0.3751\n",
      "Epoch 81/200, Validation Loss: 0.3235\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 82/200, Train Loss: 0.3729\n",
      "Epoch 82/200, Validation Loss: 0.3538\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 83/200, Train Loss: 0.3743\n",
      "Epoch 83/200, Validation Loss: 0.3358\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 84/200, Train Loss: 0.3686\n",
      "Epoch 84/200, Validation Loss: 0.3384\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 85/200, Train Loss: 0.3684\n",
      "Epoch 85/200, Validation Loss: 0.3217\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 86/200, Train Loss: 0.3662\n",
      "Epoch 86/200, Validation Loss: 0.3208\n",
      "No improvement in validation loss for 8 epoch(s).\n",
      "Epoch 87/200, Train Loss: 0.3696\n",
      "Epoch 87/200, Validation Loss: 0.3318\n",
      "No improvement in validation loss for 9 epoch(s).\n",
      "Epoch 88/200, Train Loss: 0.3736\n",
      "Epoch 88/200, Validation Loss: 0.3528\n",
      "No improvement in validation loss for 10 epoch(s).\n",
      "Epoch 89/200, Train Loss: 0.3679\n",
      "Epoch 89/200, Validation Loss: 0.3678\n",
      "No improvement in validation loss for 11 epoch(s).\n",
      "Epoch 90/200, Train Loss: 0.3760\n",
      "Epoch 90/200, Validation Loss: 0.3251\n",
      "No improvement in validation loss for 12 epoch(s).\n",
      "Epoch 91/200, Train Loss: 0.3659\n",
      "Epoch 91/200, Validation Loss: 0.3151\n",
      "Best model updated based on validation loss.\n",
      "Epoch 92/200, Train Loss: 0.3678\n",
      "Epoch 92/200, Validation Loss: 0.3170\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 93/200, Train Loss: 0.3679\n",
      "Epoch 93/200, Validation Loss: 0.3194\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 94/200, Train Loss: 0.3687\n",
      "Epoch 94/200, Validation Loss: 0.3582\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 95/200, Train Loss: 0.3717\n",
      "Epoch 95/200, Validation Loss: 0.3095\n",
      "Best model updated based on validation loss.\n",
      "Epoch 96/200, Train Loss: 0.3643\n",
      "Epoch 96/200, Validation Loss: 0.3099\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 97/200, Train Loss: 0.3632\n",
      "Epoch 97/200, Validation Loss: 0.3461\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 98/200, Train Loss: 0.3647\n",
      "Epoch 98/200, Validation Loss: 0.3325\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 99/200, Train Loss: 0.3619\n",
      "Epoch 99/200, Validation Loss: 0.3420\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 100/200, Train Loss: 0.3628\n",
      "Epoch 100/200, Validation Loss: 0.3614\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 101/200, Train Loss: 0.3616\n",
      "Epoch 101/200, Validation Loss: 0.3142\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 102/200, Train Loss: 0.3611\n",
      "Epoch 102/200, Validation Loss: 0.2991\n",
      "Best model updated based on validation loss.\n",
      "Epoch 103/200, Train Loss: 0.3639\n",
      "Epoch 103/200, Validation Loss: 0.3127\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 104/200, Train Loss: 0.3553\n",
      "Epoch 104/200, Validation Loss: 0.3200\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 105/200, Train Loss: 0.3616\n",
      "Epoch 105/200, Validation Loss: 0.3020\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 106/200, Train Loss: 0.3530\n",
      "Epoch 106/200, Validation Loss: 0.3300\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 107/200, Train Loss: 0.3542\n",
      "Epoch 107/200, Validation Loss: 0.3060\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 108/200, Train Loss: 0.3582\n",
      "Epoch 108/200, Validation Loss: 0.3348\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 109/200, Train Loss: 0.3557\n",
      "Epoch 109/200, Validation Loss: 0.3239\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 110/200, Train Loss: 0.3603\n",
      "Epoch 110/200, Validation Loss: 0.3791\n",
      "No improvement in validation loss for 8 epoch(s).\n",
      "Epoch 111/200, Train Loss: 0.3569\n",
      "Epoch 111/200, Validation Loss: 0.3948\n",
      "No improvement in validation loss for 9 epoch(s).\n",
      "Epoch 112/200, Train Loss: 0.3631\n",
      "Epoch 112/200, Validation Loss: 0.3182\n",
      "No improvement in validation loss for 10 epoch(s).\n",
      "Epoch 113/200, Train Loss: 0.3727\n",
      "Epoch 113/200, Validation Loss: 0.3468\n",
      "No improvement in validation loss for 11 epoch(s).\n",
      "Epoch 114/200, Train Loss: 0.3760\n",
      "Epoch 114/200, Validation Loss: 0.3377\n",
      "No improvement in validation loss for 12 epoch(s).\n",
      "Epoch 115/200, Train Loss: 0.3718\n",
      "Epoch 115/200, Validation Loss: 0.3153\n",
      "No improvement in validation loss for 13 epoch(s).\n",
      "Epoch 116/200, Train Loss: 0.3675\n",
      "Epoch 116/200, Validation Loss: 0.3262\n",
      "No improvement in validation loss for 14 epoch(s).\n",
      "Epoch 117/200, Train Loss: 0.3686\n",
      "Epoch 117/200, Validation Loss: 0.3255\n",
      "No improvement in validation loss for 15 epoch(s).\n",
      "Epoch 118/200, Train Loss: 0.3641\n",
      "Epoch 118/200, Validation Loss: 0.3195\n",
      "No improvement in validation loss for 16 epoch(s).\n",
      "Epoch 119/200, Train Loss: 0.3690\n",
      "Epoch 119/200, Validation Loss: 0.3057\n",
      "No improvement in validation loss for 17 epoch(s).\n",
      "Epoch 120/200, Train Loss: 0.3632\n",
      "Epoch 120/200, Validation Loss: 0.3264\n",
      "No improvement in validation loss for 18 epoch(s).\n",
      "Epoch 121/200, Train Loss: 0.3614\n",
      "Epoch 121/200, Validation Loss: 0.3145\n",
      "No improvement in validation loss for 19 epoch(s).\n",
      "Epoch 122/200, Train Loss: 0.3617\n",
      "Epoch 122/200, Validation Loss: 0.3131\n",
      "No improvement in validation loss for 20 epoch(s).\n",
      "Epoch 123/200, Train Loss: 0.3606\n",
      "Epoch 123/200, Validation Loss: 0.3155\n",
      "No improvement in validation loss for 21 epoch(s).\n",
      "Epoch 124/200, Train Loss: 0.3547\n",
      "Epoch 124/200, Validation Loss: 0.3254\n",
      "No improvement in validation loss for 22 epoch(s).\n",
      "Epoch 125/200, Train Loss: 0.3659\n",
      "Epoch 125/200, Validation Loss: 0.3171\n",
      "No improvement in validation loss for 23 epoch(s).\n",
      "Epoch 126/200, Train Loss: 0.3640\n",
      "Epoch 126/200, Validation Loss: 0.3187\n",
      "No improvement in validation loss for 24 epoch(s).\n",
      "Epoch 127/200, Train Loss: 0.3590\n",
      "Epoch 127/200, Validation Loss: 0.3485\n",
      "No improvement in validation loss for 25 epoch(s).\n",
      "Epoch 128/200, Train Loss: 0.3626\n",
      "Epoch 128/200, Validation Loss: 0.3431\n",
      "No improvement in validation loss for 26 epoch(s).\n",
      "Epoch 129/200, Train Loss: 0.3633\n",
      "Epoch 129/200, Validation Loss: 0.3221\n",
      "No improvement in validation loss for 27 epoch(s).\n",
      "Epoch 130/200, Train Loss: 0.3563\n",
      "Epoch 130/200, Validation Loss: 0.3963\n",
      "No improvement in validation loss for 28 epoch(s).\n",
      "Epoch 131/200, Train Loss: 0.3558\n",
      "Epoch 131/200, Validation Loss: 0.2967\n",
      "Best model updated based on validation loss.\n",
      "Epoch 132/200, Train Loss: 0.3654\n",
      "Epoch 132/200, Validation Loss: 0.3057\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 133/200, Train Loss: 0.3529\n",
      "Epoch 133/200, Validation Loss: 0.3117\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 134/200, Train Loss: 0.3534\n",
      "Epoch 134/200, Validation Loss: 0.3045\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 135/200, Train Loss: 0.3589\n",
      "Epoch 135/200, Validation Loss: 0.4181\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 136/200, Train Loss: 0.3491\n",
      "Epoch 136/200, Validation Loss: 0.3049\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 137/200, Train Loss: 0.3579\n",
      "Epoch 137/200, Validation Loss: 0.3048\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 138/200, Train Loss: 0.3590\n",
      "Epoch 138/200, Validation Loss: 0.2964\n",
      "Best model updated based on validation loss.\n",
      "Epoch 139/200, Train Loss: 0.3564\n",
      "Epoch 139/200, Validation Loss: 0.3225\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 140/200, Train Loss: 0.3512\n",
      "Epoch 140/200, Validation Loss: 0.2891\n",
      "Best model updated based on validation loss.\n",
      "Epoch 141/200, Train Loss: 0.3526\n",
      "Epoch 141/200, Validation Loss: 0.2941\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 142/200, Train Loss: 0.3507\n",
      "Epoch 142/200, Validation Loss: 0.3163\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 143/200, Train Loss: 0.3494\n",
      "Epoch 143/200, Validation Loss: 0.4269\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 144/200, Train Loss: 0.3484\n",
      "Epoch 144/200, Validation Loss: 0.3170\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 145/200, Train Loss: 0.3503\n",
      "Epoch 145/200, Validation Loss: 0.3138\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 146/200, Train Loss: 0.3469\n",
      "Epoch 146/200, Validation Loss: 0.2906\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 147/200, Train Loss: 0.3484\n",
      "Epoch 147/200, Validation Loss: 0.2993\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 148/200, Train Loss: 0.3509\n",
      "Epoch 148/200, Validation Loss: 0.2933\n",
      "No improvement in validation loss for 8 epoch(s).\n",
      "Epoch 149/200, Train Loss: 0.3516\n",
      "Epoch 149/200, Validation Loss: 0.3357\n",
      "No improvement in validation loss for 9 epoch(s).\n",
      "Epoch 150/200, Train Loss: 0.3517\n",
      "Epoch 150/200, Validation Loss: 0.3219\n",
      "No improvement in validation loss for 10 epoch(s).\n",
      "Epoch 151/200, Train Loss: 0.3426\n",
      "Epoch 151/200, Validation Loss: 0.3102\n",
      "No improvement in validation loss for 11 epoch(s).\n",
      "Epoch 152/200, Train Loss: 0.3506\n",
      "Epoch 152/200, Validation Loss: 0.3179\n",
      "No improvement in validation loss for 12 epoch(s).\n",
      "Epoch 153/200, Train Loss: 0.3457\n",
      "Epoch 153/200, Validation Loss: 0.3146\n",
      "No improvement in validation loss for 13 epoch(s).\n",
      "Epoch 154/200, Train Loss: 0.3507\n",
      "Epoch 154/200, Validation Loss: 0.3210\n",
      "No improvement in validation loss for 14 epoch(s).\n",
      "Epoch 155/200, Train Loss: 0.3474\n",
      "Epoch 155/200, Validation Loss: 0.3695\n",
      "No improvement in validation loss for 15 epoch(s).\n",
      "Epoch 156/200, Train Loss: 0.3675\n",
      "Epoch 156/200, Validation Loss: 0.3048\n",
      "No improvement in validation loss for 16 epoch(s).\n",
      "Epoch 157/200, Train Loss: 0.3461\n",
      "Epoch 157/200, Validation Loss: 0.2935\n",
      "No improvement in validation loss for 17 epoch(s).\n",
      "Epoch 158/200, Train Loss: 0.3463\n",
      "Epoch 158/200, Validation Loss: 0.3304\n",
      "No improvement in validation loss for 18 epoch(s).\n",
      "Epoch 159/200, Train Loss: 0.3485\n",
      "Epoch 159/200, Validation Loss: 0.2943\n",
      "No improvement in validation loss for 19 epoch(s).\n",
      "Epoch 160/200, Train Loss: 0.3492\n",
      "Epoch 160/200, Validation Loss: 0.3148\n",
      "No improvement in validation loss for 20 epoch(s).\n",
      "Epoch 161/200, Train Loss: 0.3464\n",
      "Epoch 161/200, Validation Loss: 0.2952\n",
      "No improvement in validation loss for 21 epoch(s).\n",
      "Epoch 162/200, Train Loss: 0.3460\n",
      "Epoch 162/200, Validation Loss: 0.2947\n",
      "No improvement in validation loss for 22 epoch(s).\n",
      "Epoch 163/200, Train Loss: 0.3493\n",
      "Epoch 163/200, Validation Loss: 0.2906\n",
      "No improvement in validation loss for 23 epoch(s).\n",
      "Epoch 164/200, Train Loss: 0.3457\n",
      "Epoch 164/200, Validation Loss: 0.3256\n",
      "No improvement in validation loss for 24 epoch(s).\n",
      "Epoch 165/200, Train Loss: 0.3466\n",
      "Epoch 165/200, Validation Loss: 0.3030\n",
      "No improvement in validation loss for 25 epoch(s).\n",
      "Epoch 166/200, Train Loss: 0.3497\n",
      "Epoch 166/200, Validation Loss: 0.2902\n",
      "No improvement in validation loss for 26 epoch(s).\n",
      "Epoch 167/200, Train Loss: 0.3457\n",
      "Epoch 167/200, Validation Loss: 0.3021\n",
      "No improvement in validation loss for 27 epoch(s).\n",
      "Epoch 168/200, Train Loss: 0.3481\n",
      "Epoch 168/200, Validation Loss: 0.2853\n",
      "Best model updated based on validation loss.\n",
      "Epoch 169/200, Train Loss: 0.3468\n",
      "Epoch 169/200, Validation Loss: 0.3527\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 170/200, Train Loss: 0.3426\n",
      "Epoch 170/200, Validation Loss: 0.3027\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 171/200, Train Loss: 0.3452\n",
      "Epoch 171/200, Validation Loss: 0.3070\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 172/200, Train Loss: 0.3434\n",
      "Epoch 172/200, Validation Loss: 0.3646\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 173/200, Train Loss: 0.3539\n",
      "Epoch 173/200, Validation Loss: 0.3459\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 174/200, Train Loss: 0.3478\n",
      "Epoch 174/200, Validation Loss: 0.3084\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 175/200, Train Loss: 0.3429\n",
      "Epoch 175/200, Validation Loss: 0.2976\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 176/200, Train Loss: 0.3410\n",
      "Epoch 176/200, Validation Loss: 0.2816\n",
      "Best model updated based on validation loss.\n",
      "Epoch 177/200, Train Loss: 0.3407\n",
      "Epoch 177/200, Validation Loss: 0.2928\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 178/200, Train Loss: 0.3417\n",
      "Epoch 178/200, Validation Loss: 0.2941\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 179/200, Train Loss: 0.3415\n",
      "Epoch 179/200, Validation Loss: 0.2868\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 180/200, Train Loss: 0.3441\n",
      "Epoch 180/200, Validation Loss: 0.3369\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 181/200, Train Loss: 0.3407\n",
      "Epoch 181/200, Validation Loss: 0.2947\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Epoch 182/200, Train Loss: 0.3399\n",
      "Epoch 182/200, Validation Loss: 0.3148\n",
      "No improvement in validation loss for 6 epoch(s).\n",
      "Epoch 183/200, Train Loss: 0.3461\n",
      "Epoch 183/200, Validation Loss: 0.3111\n",
      "No improvement in validation loss for 7 epoch(s).\n",
      "Epoch 184/200, Train Loss: 0.3408\n",
      "Epoch 184/200, Validation Loss: 0.2984\n",
      "No improvement in validation loss for 8 epoch(s).\n",
      "Epoch 185/200, Train Loss: 0.3453\n",
      "Epoch 185/200, Validation Loss: 0.2958\n",
      "No improvement in validation loss for 9 epoch(s).\n",
      "Epoch 186/200, Train Loss: 0.3411\n",
      "Epoch 186/200, Validation Loss: 0.3543\n",
      "No improvement in validation loss for 10 epoch(s).\n",
      "Epoch 187/200, Train Loss: 0.3370\n",
      "Epoch 187/200, Validation Loss: 0.3194\n",
      "No improvement in validation loss for 11 epoch(s).\n",
      "Epoch 188/200, Train Loss: 0.3400\n",
      "Epoch 188/200, Validation Loss: 0.2985\n",
      "No improvement in validation loss for 12 epoch(s).\n",
      "Epoch 189/200, Train Loss: 0.3421\n",
      "Epoch 189/200, Validation Loss: 0.2947\n",
      "No improvement in validation loss for 13 epoch(s).\n",
      "Epoch 190/200, Train Loss: 0.3504\n",
      "Epoch 190/200, Validation Loss: 0.5113\n",
      "No improvement in validation loss for 14 epoch(s).\n",
      "Epoch 191/200, Train Loss: 0.3895\n",
      "Epoch 191/200, Validation Loss: 0.3536\n",
      "No improvement in validation loss for 15 epoch(s).\n",
      "Epoch 192/200, Train Loss: 0.3724\n",
      "Epoch 192/200, Validation Loss: 0.3482\n",
      "No improvement in validation loss for 16 epoch(s).\n",
      "Epoch 193/200, Train Loss: 0.3706\n",
      "Epoch 193/200, Validation Loss: 0.3260\n",
      "No improvement in validation loss for 17 epoch(s).\n",
      "Epoch 194/200, Train Loss: 0.3681\n",
      "Epoch 194/200, Validation Loss: 0.3648\n",
      "No improvement in validation loss for 18 epoch(s).\n",
      "Epoch 195/200, Train Loss: 0.3621\n",
      "Epoch 195/200, Validation Loss: 0.3156\n",
      "No improvement in validation loss for 19 epoch(s).\n",
      "Epoch 196/200, Train Loss: 0.3549\n",
      "Epoch 196/200, Validation Loss: 0.3890\n",
      "No improvement in validation loss for 20 epoch(s).\n",
      "Epoch 197/200, Train Loss: 0.3586\n",
      "Epoch 197/200, Validation Loss: 0.3229\n",
      "No improvement in validation loss for 21 epoch(s).\n",
      "Epoch 198/200, Train Loss: 0.3577\n",
      "Epoch 198/200, Validation Loss: 0.2983\n",
      "No improvement in validation loss for 22 epoch(s).\n",
      "Epoch 199/200, Train Loss: 0.3444\n",
      "Epoch 199/200, Validation Loss: 0.3288\n",
      "No improvement in validation loss for 23 epoch(s).\n",
      "Epoch 200/200, Train Loss: 0.3390\n",
      "Epoch 200/200, Validation Loss: 0.3085\n",
      "No improvement in validation loss for 24 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6008562949847202,\n",
       "  0.5480331417046437,\n",
       "  0.5140289214598078,\n",
       "  0.5016015982546774,\n",
       "  0.49479288449701,\n",
       "  0.4864212267050127,\n",
       "  0.48441995957068035,\n",
       "  0.4803346953018993,\n",
       "  0.47544477911425287,\n",
       "  0.47714753536140025,\n",
       "  0.4689003493712873,\n",
       "  0.4724037250795332,\n",
       "  0.4667307401494104,\n",
       "  0.46720050827783793,\n",
       "  0.45809665096252145,\n",
       "  0.4537135568605799,\n",
       "  0.45432859606483356,\n",
       "  0.44998934735246254,\n",
       "  0.44436074299674455,\n",
       "  0.43980160770164867,\n",
       "  0.4387836659948031,\n",
       "  0.436389524859636,\n",
       "  0.4339868102045286,\n",
       "  0.4271774517536974,\n",
       "  0.4279398167670584,\n",
       "  0.4215802162530876,\n",
       "  0.4140019304543531,\n",
       "  0.41307377680933394,\n",
       "  0.416804173700258,\n",
       "  0.41743117098500127,\n",
       "  0.41109074648140237,\n",
       "  0.4094439540387822,\n",
       "  0.4061598718571825,\n",
       "  0.40508430182021493,\n",
       "  0.4043254139218606,\n",
       "  0.4048911755790516,\n",
       "  0.4030485005200315,\n",
       "  0.396831979982707,\n",
       "  0.4011652249260014,\n",
       "  0.39944573632713887,\n",
       "  0.39981848418104404,\n",
       "  0.4031710129509978,\n",
       "  0.3974880903199011,\n",
       "  0.3939220415947794,\n",
       "  0.3948665178551966,\n",
       "  0.40032242100153653,\n",
       "  0.39504483069996443,\n",
       "  0.38743276129774495,\n",
       "  0.3914839642996691,\n",
       "  0.3895888478678911,\n",
       "  0.3871688088642902,\n",
       "  0.3882422644416897,\n",
       "  0.3859245987875121,\n",
       "  0.3934398399019728,\n",
       "  0.3915133165157571,\n",
       "  0.38566581248020637,\n",
       "  0.38795149377008686,\n",
       "  0.3811432584664043,\n",
       "  0.3838665253856555,\n",
       "  0.38708509294962395,\n",
       "  0.3790613568660353,\n",
       "  0.38052351357681413,\n",
       "  0.376767527236014,\n",
       "  0.3773494472359719,\n",
       "  0.3805890355639312,\n",
       "  0.3731993238232574,\n",
       "  0.37845003028609314,\n",
       "  0.3779980089794211,\n",
       "  0.3811195639120478,\n",
       "  0.3801173448968096,\n",
       "  0.3794093861871836,\n",
       "  0.37492621408737437,\n",
       "  0.3743172509431028,\n",
       "  0.37038365240607946,\n",
       "  0.37095465059487187,\n",
       "  0.3776459639017679,\n",
       "  0.3693360390154277,\n",
       "  0.3728701711714673,\n",
       "  0.38036334621054785,\n",
       "  0.3725787669572295,\n",
       "  0.375146963406785,\n",
       "  0.37286536510096113,\n",
       "  0.37433878864307385,\n",
       "  0.3686087200734891,\n",
       "  0.368422763343571,\n",
       "  0.3661984727546877,\n",
       "  0.36960567895855223,\n",
       "  0.37361010907559977,\n",
       "  0.36786050747851934,\n",
       "  0.37603777667798965,\n",
       "  0.3659159076558489,\n",
       "  0.367843526981923,\n",
       "  0.36792547928840935,\n",
       "  0.3686898368860589,\n",
       "  0.3717313587285426,\n",
       "  0.36425299153846946,\n",
       "  0.3632139373697391,\n",
       "  0.3647466766743027,\n",
       "  0.36186937973105987,\n",
       "  0.3627947835948597,\n",
       "  0.36158797429735157,\n",
       "  0.3611298222576274,\n",
       "  0.36387007424519174,\n",
       "  0.3552963954960408,\n",
       "  0.3615861823617601,\n",
       "  0.3530395147701105,\n",
       "  0.3541968669818372,\n",
       "  0.358200683211591,\n",
       "  0.3556515402990539,\n",
       "  0.36025010950508574,\n",
       "  0.35685377908097643,\n",
       "  0.3631265635494472,\n",
       "  0.3727498964539596,\n",
       "  0.3759564450327434,\n",
       "  0.3717762435121196,\n",
       "  0.3674703518904391,\n",
       "  0.3685971390126514,\n",
       "  0.3641334942155549,\n",
       "  0.3689631922157849,\n",
       "  0.3631908500833171,\n",
       "  0.36139695990045057,\n",
       "  0.3616881963347091,\n",
       "  0.3605627216195979,\n",
       "  0.3547004137847091,\n",
       "  0.36593100043887994,\n",
       "  0.3639850582344597,\n",
       "  0.35899587991286297,\n",
       "  0.36261022678342,\n",
       "  0.36326690172257065,\n",
       "  0.3562605297636418,\n",
       "  0.3558031157926232,\n",
       "  0.36544306674579374,\n",
       "  0.3529357984459319,\n",
       "  0.3534179513906541,\n",
       "  0.3589193533624516,\n",
       "  0.34912054846886875,\n",
       "  0.35791044248914233,\n",
       "  0.35903686978379074,\n",
       "  0.356387779121699,\n",
       "  0.3511877180767708,\n",
       "  0.35255345579515507,\n",
       "  0.350703051519029,\n",
       "  0.3493937234033127,\n",
       "  0.3483589989646357,\n",
       "  0.3503386584116894,\n",
       "  0.34688209779307144,\n",
       "  0.3484424831054243,\n",
       "  0.35091341450607694,\n",
       "  0.3515711812999378,\n",
       "  0.3516981484989325,\n",
       "  0.3426454097235284,\n",
       "  0.3505975798583355,\n",
       "  0.3456844844430888,\n",
       "  0.35069246181622654,\n",
       "  0.3473615674542732,\n",
       "  0.3675283417105675,\n",
       "  0.34607199601018107,\n",
       "  0.34627636026362985,\n",
       "  0.3485196142172327,\n",
       "  0.34922283514827285,\n",
       "  0.34635171017983335,\n",
       "  0.3459506653604053,\n",
       "  0.34932240257863284,\n",
       "  0.3457355742501158,\n",
       "  0.34662765712052784,\n",
       "  0.34968605768315647,\n",
       "  0.34567482391891835,\n",
       "  0.3480711848658769,\n",
       "  0.34680431635708225,\n",
       "  0.3426010251501385,\n",
       "  0.34516188501298023,\n",
       "  0.34341261643840343,\n",
       "  0.35394356750762784,\n",
       "  0.34779117572419094,\n",
       "  0.3428670100563643,\n",
       "  0.3410307935458057,\n",
       "  0.34070963134520316,\n",
       "  0.34170900237093976,\n",
       "  0.3415424444490955,\n",
       "  0.34414140122885606,\n",
       "  0.3407334956891683,\n",
       "  0.3399387477814746,\n",
       "  0.3460623332635075,\n",
       "  0.34075659852550955,\n",
       "  0.3452811434636919,\n",
       "  0.3411355176142284,\n",
       "  0.33704630538922586,\n",
       "  0.3400056184174455,\n",
       "  0.34207218211321605,\n",
       "  0.35041921607085635,\n",
       "  0.38954578581563876,\n",
       "  0.3724246809803912,\n",
       "  0.37061125443500725,\n",
       "  0.368147422951095,\n",
       "  0.3621203249409085,\n",
       "  0.354861822095858,\n",
       "  0.35855159564894074,\n",
       "  0.35774416266655434,\n",
       "  0.3444236998401937,\n",
       "  0.33900318617622055],\n",
       " [0.5946027082362632,\n",
       "  0.5568551616610432,\n",
       "  0.4815213704546212,\n",
       "  0.4894441064530623,\n",
       "  0.4689571819820132,\n",
       "  0.45673271355099687,\n",
       "  0.4584889958504504,\n",
       "  0.6270103118327387,\n",
       "  0.4827524494311474,\n",
       "  0.4421647809855564,\n",
       "  0.47012188620941214,\n",
       "  0.44542685393888937,\n",
       "  0.44861958538563335,\n",
       "  0.45640360195258,\n",
       "  0.4234624024624737,\n",
       "  0.5464510911593855,\n",
       "  0.42718863575254584,\n",
       "  0.4202106129795374,\n",
       "  0.40642299217811184,\n",
       "  0.4291816847873074,\n",
       "  0.5165754500207493,\n",
       "  0.43813500497224617,\n",
       "  0.39412355931312637,\n",
       "  0.4552910738527896,\n",
       "  0.4084360245046208,\n",
       "  0.4559991914483049,\n",
       "  0.3968872532491286,\n",
       "  0.4023746585591019,\n",
       "  0.41058853784549504,\n",
       "  0.4140422948144847,\n",
       "  0.4050610535559975,\n",
       "  0.5560386662813408,\n",
       "  0.36243011857062396,\n",
       "  0.3565233633862979,\n",
       "  0.3562116277557769,\n",
       "  0.44435300873763206,\n",
       "  0.4071501476762251,\n",
       "  0.713211947843402,\n",
       "  0.3951272116537735,\n",
       "  0.38656573240358816,\n",
       "  0.4132544974020688,\n",
       "  0.3970447905407175,\n",
       "  0.5682464428018407,\n",
       "  0.3716480684923786,\n",
       "  0.36843828683958035,\n",
       "  0.5785309586469122,\n",
       "  0.38342209961530876,\n",
       "  0.34664692937599423,\n",
       "  0.4682372108466028,\n",
       "  0.34408830400639784,\n",
       "  0.3730875280080648,\n",
       "  0.4987503943278202,\n",
       "  0.4305116492352029,\n",
       "  0.33213609754432244,\n",
       "  0.33261077069580675,\n",
       "  0.5057356529347523,\n",
       "  0.35714561738028305,\n",
       "  0.3988013863867024,\n",
       "  0.3323302797199267,\n",
       "  0.3276918235475808,\n",
       "  0.3747118612535131,\n",
       "  0.3271338736786376,\n",
       "  0.34724330076617765,\n",
       "  0.3255252162878479,\n",
       "  0.34401615432894156,\n",
       "  0.3739887980361092,\n",
       "  0.3539628288926758,\n",
       "  0.3368351946142929,\n",
       "  0.3831622886894434,\n",
       "  0.3210766825923609,\n",
       "  0.3475670678704188,\n",
       "  0.32222788284728093,\n",
       "  0.32283399337542273,\n",
       "  0.3617338421024276,\n",
       "  0.3402369230864247,\n",
       "  0.31928608674260117,\n",
       "  0.3294534005239879,\n",
       "  0.3151136209729247,\n",
       "  0.3913290702155554,\n",
       "  0.43079102949795073,\n",
       "  0.3235350322061789,\n",
       "  0.353754828166209,\n",
       "  0.33576588525366635,\n",
       "  0.3383984441609101,\n",
       "  0.32174004453505617,\n",
       "  0.3208461935705906,\n",
       "  0.3317553788089704,\n",
       "  0.3527510818966537,\n",
       "  0.36780423916830796,\n",
       "  0.3250780597996809,\n",
       "  0.3151010305690911,\n",
       "  0.31704233790123776,\n",
       "  0.31938503993686496,\n",
       "  0.3582269051804562,\n",
       "  0.3094775002229724,\n",
       "  0.3098964959595451,\n",
       "  0.3460917911073098,\n",
       "  0.3325072813119034,\n",
       "  0.34202140939939774,\n",
       "  0.36138135989911685,\n",
       "  0.3141706814105545,\n",
       "  0.29909977392727877,\n",
       "  0.3127269936676181,\n",
       "  0.3200073847186784,\n",
       "  0.3019834813754816,\n",
       "  0.32995044711650995,\n",
       "  0.30604308785950335,\n",
       "  0.33484725127577053,\n",
       "  0.3239056352230051,\n",
       "  0.37906505437586796,\n",
       "  0.39484846262667184,\n",
       "  0.3182317591186939,\n",
       "  0.3468442489743961,\n",
       "  0.33765915339687447,\n",
       "  0.3153487163958142,\n",
       "  0.32615719658233483,\n",
       "  0.3254842068203355,\n",
       "  0.31952291026013446,\n",
       "  0.3057449469741153,\n",
       "  0.3264108696713467,\n",
       "  0.31453944545413715,\n",
       "  0.3130636691531193,\n",
       "  0.315524670217649,\n",
       "  0.3254416873431983,\n",
       "  0.3171402166641171,\n",
       "  0.3186643979153662,\n",
       "  0.3484760813278482,\n",
       "  0.34308538859038634,\n",
       "  0.32214395167749915,\n",
       "  0.3963171643965599,\n",
       "  0.2966766366222968,\n",
       "  0.3056876956961305,\n",
       "  0.31173918815045154,\n",
       "  0.3044734096454263,\n",
       "  0.41811467779993766,\n",
       "  0.3048828552854522,\n",
       "  0.30482560478135673,\n",
       "  0.2964087277954319,\n",
       "  0.322543642792828,\n",
       "  0.28905525107065677,\n",
       "  0.2940854493323751,\n",
       "  0.31634216043953983,\n",
       "  0.4268916624839097,\n",
       "  0.3170336628154436,\n",
       "  0.31384890268570054,\n",
       "  0.2905517486350842,\n",
       "  0.29931750612868313,\n",
       "  0.2933055815986849,\n",
       "  0.33570458785518853,\n",
       "  0.3218948763250819,\n",
       "  0.3102277047067213,\n",
       "  0.31787098617939746,\n",
       "  0.3145761532659686,\n",
       "  0.3209737965840915,\n",
       "  0.36952749844602556,\n",
       "  0.30483737886862455,\n",
       "  0.2935198022246118,\n",
       "  0.33035064669223524,\n",
       "  0.29429254401664867,\n",
       "  0.31481014601810403,\n",
       "  0.29515454124530316,\n",
       "  0.29469953943233623,\n",
       "  0.2906433994106023,\n",
       "  0.32563761887263865,\n",
       "  0.3029803161313966,\n",
       "  0.2901562728185032,\n",
       "  0.3020873631060488,\n",
       "  0.2853098835667136,\n",
       "  0.35273719316466035,\n",
       "  0.302662670703381,\n",
       "  0.3070417978704097,\n",
       "  0.364635154665609,\n",
       "  0.3459462344707151,\n",
       "  0.3084406027999041,\n",
       "  0.2976058323368764,\n",
       "  0.2816387563336891,\n",
       "  0.2928235074258628,\n",
       "  0.29411373419455744,\n",
       "  0.2868146852508582,\n",
       "  0.33689824555471326,\n",
       "  0.29466274802529396,\n",
       "  0.314835031427701,\n",
       "  0.3111287426590434,\n",
       "  0.2983509507144056,\n",
       "  0.2957852531049985,\n",
       "  0.35427295700352934,\n",
       "  0.31937792080847166,\n",
       "  0.29853866313054944,\n",
       "  0.2946975809766659,\n",
       "  0.5113429372064208,\n",
       "  0.3536447445328998,\n",
       "  0.34819230249117444,\n",
       "  0.3260144972813348,\n",
       "  0.36476466991386686,\n",
       "  0.3156383789150147,\n",
       "  0.38899382956462575,\n",
       "  0.32291373176511584,\n",
       "  0.298315291082422,\n",
       "  0.32876212567151686,\n",
       "  0.30853476695519116])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, train_config, model_checkpoints_path + \"/booster/\" + match + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0dd508-da62-471d-9f51-9591f81f480f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:10:36.172738Z",
     "start_time": "2025-02-05T11:10:36.160626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model after training\n",
    "model.load_state_dict(torch.load(model_checkpoints_path + \"/booster/\" + match + \".pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b3252d-6cef-4e4d-9241-f27955ee9df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:10:36.578332Z",
     "start_time": "2025-02-05T11:10:36.202374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATConv(10, 128, heads=1)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): GATConv(128, 64, heads=1)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "[np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n",
      "Accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "true_values, predicted_values, accuracy = evaluate(device, model, test_loader, model_checkpoints_path + \"/booster/\" + match + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a169f2fa-cb48-404e-b976-d685b6405638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:10:36.678476Z",
     "start_time": "2025-02-05T11:10:36.592973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAHHCAYAAAAiSltoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVjlJREFUeJzt3Qd8E/X7B/Cng7bMsssqW/YuiKgs2ShD8KcoArIUBGTIEGWDgqDsJSBTUIagLNkyhLIKyEYZShFomS0t0EKb/+vz1cs/SZOSNOnKfd6+zpLc5XK5XO6e7/Md52EwGAxCREREuuWZ2htAREREqYvBABERkc4xGCAiItI5BgNEREQ6x2CAiIhI5xgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0Ll0HA3/++ac0btxY/P39xcPDQ3766SeXrv+vv/5S6128eLFL15ue1atXT02uEhUVJd26dZN8+fKpfd2vXz+XrZtcB78BfD9Hjx5N7U0horQYDFy6dEk++OADKV68uPj5+Um2bNnkpZdekmnTpsmjR48kOXXq1ElOnToln3/+uSxbtkyqV68u7uK9995TJ1/sT2v7EYEQ5mP66quvHF7/9evXZdSoUXLixAlJTV988YW60PTs2VN9hx06dEj294yPj5elS5dKo0aNJHfu3JIhQwbJmzevCiznzZsnMTExVl93//59dYxjn587d874PPaj9l0kNiUWRGkXW0y//fZbgvkYNTwwMFDNf+2115K8r10dMDtr/vz5UrduXQkICBBfX18pVqyYdO7cWQXi9jh//rwMHjxYqlSpIlmzZpX8+fPLq6++muxBy+bNm9V3UaBAAXU8kXP++ecfefPNNyV79uzqnNeqVSu5fPmyXa/F/p87d646BrJkyaKOpWbNmsmBAwcSLBsSEiJNmzZV74HjBb/51D4HphXezrx406ZN8r///U/9iDt27CgVKlSQ2NhYdTIbNGiQnDlzRp1ckwMukMHBwfLZZ59J7969k+U9ihQpot4HF4vU4O3tLQ8fPpQNGzaoH4qp5cuXqwvT48ePk7RuBAOjR4+WokWLqh+RvbZt2yautGvXLnnhhRdk5MiRkhLwfb7++uuydetWefHFF2XgwIHq5HH37l3Zs2ePfPjhh3Lo0CH59ttvE7x29erV6gKALAb2/7hx49Tzbdq0kZIlS5plOxDc4H0wT4P3eRZ8pytWrJCXX37Z7Hls27Vr19RvLakQDLzxxhvSunVrSSuOHz+uAoCWLVtKjhw55MqVKypA2Lhxo/z+++/qYpuYBQsWqO+qbdu26ruLiIiQb775Rh1TW7ZskYYNGybLduP7x28HQQuO4eR6Hz3A76V+/frqu/v000/V+XbKlCkqSMSFOleuXIm+HteayZMny7vvvquOAQTtOAbw+v3798vzzz+vljt27Jj6XSGoxvkGQcTs2bPVcocPH5bSpUuLrhmS6PLly4YsWbIYypQpY7h+/XqC+X/++adh6tSphuTy999/4wZLhkmTJhncUadOnQyZM2c2NG7c2NC6desE85977jlD27Ztk7wPjhw5ol67aNEiu5aPjo42JIdixYoZXn31VZet78mTJ4aYmBib8z/44AP1uW0dm3/88Ydh1qxZVufVqVPH0KZNG0P//v3Vdtty69Yt9R4jR460e7vxPeA1WH/u3LnV5zDVvXt3Q1BQkKFIkSJJ3l84nnBcJYW2fThuktvRo0fVe40fP96uZR88eGD23O3btw158uQxvPTSS8myfVFRUWpfTp8+3VC1alXDe++9Z0irsK1p3Zdffqm+78OHDxufO3funMHLy8swdOjQRF+L30nGjBkNb7zxRoLrE9b50UcfGZ9r3ry5IUeOHOr40ODahetYmzZtDHqX5GCgR48eamfv37/fruXxpY0ZM8ZQvHhxg4+Pjzqp4Yt+/Pix2XLayW7fvn2GGjVqGHx9fdWJd8mSJcZlcJLFe5tOeB3gZKf925T2GlPbtm1TJwx/f3/14y5VqpTZwXflyhWrF8ydO3caXn75ZUOmTJnUa1u2bGk4e/as1fdDUIRtwnLZsmVTJw57LqxaMLB48WK1D+7du2echx8N1v3jjz8mCAbu3Llj+Pjjjw0VKlRQr8+aNauhadOmhhMnThiX+fXXXxPsP9PPWbduXUP58uXVibZ27drqx9a3b1/jPEyajh07qu2z/PwIYrJnz274559/rH4+W9uAfQ5hYWGGLl26GPLmzavWX6lSJbUvTGnfDz7/lClT1LHl6elpOH78uNX3vHr1qjrBYH8kJfj08PAwrFq1ynDo0KFEj31ngoHVq1er99m8ebNxHoIbnMS+/vprq8EAPn+tWrUMOXPmNPj5+RmqVaum1mPK2r42DQyuXbum9nf+/PnV77No0aLqN64FVtr2/fbbbyoYQsCC4x+Banh4uNl73b9/X53M8TcpcLLGew0ZMsSQVDi5Y38kh2XLlqnj7MaNG+pCht/1o0ePEiyH53AMIHDHMZwvXz7D66+/brh48aJxmbi4OBWY4veKZbBfmzRpYgy6bJ2DwPIY0845Z86cMbz99tvq91elShU17/fff1ffN86leJ+AgABD586dzS6M9hwLly5dUu8xefLkBK/D7wHzVqxYoc5xOAbwW3gWnOcxWcI5pESJEom+9uHDh+o9e/XqlSAIwndkegzhXPi///0vwTrwe/Lx8UkQVOpNktsMIHWNdgJItdoDjcRGjBgh1apVM6aAxo8fL+3atUuw7MWLF1U6E3W6X3/9tUofog4d1Q6A1CvWAW+//baqa546dapD2491oe4V9cNjxoxR74NUJdJKidmxY4c0adJEwsPDVV3xgAEDVN0U2klYq+dEev/Bgwfqs+LfqBtGet5e+KxITa9du9b4HNLIZcqUUfvSEurZUC+Mz4bUGVJoaFeB/Y2qAShbtqz6zPD++++r/YepTp06xvXcuXNH1buhCgH7Fmk8a9A2JE+ePKr9RlxcnHoOKTpUJ8yYMcNmmhfbgPdEnT3eQ9sGrAupfNSv43H79u1l0qRJqpEojgG8n6VFixap98JnwfeYM2dOq+/5yy+/qG1EOtFR33//vWTOnFntV6QdS5QooVLFrobUc61atdT7mW43UqjWfiuAfVK1alX1naIqANVLqL5DNZ4G+xJVDLVr1zbua7T1ARwX+Ew//PCDvPXWWzJ9+nTVdgNVE6imMtWnTx+VvkeaFVUhOA9YVtOtW7dOfb/4ay8cb/hNoa4fbQagQYMGklQ3b95Ux1ZywPeO3wOqi/Cd4PeN/WAKxxmOFfzWg4KC1HHZt29f9T2ePn3auFzXrl1Vo1mkrr/88kv55JNPVFXRwYMHk7x9+O7xveFY6N69u3pu+/bt6tyAfYvfCrYb33fz5s1VexTNs44FnPNxrrN27OM51MOjvh9pdxwDM2fOTHRbkao/efKk1fZe2A60ScP+tSVjxoxSs2ZNdV7F+1+9elWtD+cKXDdwTtDgXI/lLWXKlElVb5t+L7qUlAgiIiJCRWOtWrWya3mUSrF8t27dzJ4fOHCgen7Xrl3G51DywXN79+41PoeSB6JZlHitlQpN2ZsZQEkSjxOLXK1F5Yi0UVpFCVyDqBtRKErJlu+HCNsUSga5cuWy+Z6mnwMle0AKrEGDBsaSBEoYo0ePtroPkGnBMpafA/sPmRl7qglQ8se8uXPnWp1nmhmArVu3quXHjRtnrD6yVrVhjbWSLkpKWN93331nfC42NlaVfrHuyMhI4+fCciiZWZZOrUGJFsubZkkAJR4cB9pkrbRUsWJFQ/v27Y2PP/30U6vpfGczA/heZs6cqUoxKPUASjP169e3ub+05Uz3FUqar7zyil3VBDhucfxaqwKIj483276GDRsan9P2KbItplkAbVl7q6AAx6eWscDvAyn4pMK5A9mV4cOHG1wNGStvb2/D/Pnzjc+9+OKLCc6FCxcutFmC1vYfznuWqWzLZZKSGUBWwJLlMQLff/99gnOtPcfCN998o16Hkr/pMYffg3Z8aZm/Z/0GtN+K6blJg+o6zDt//nyi60D2Fdkw06wXsoSWr8NvGNnfp0+fmv32CxcurF6zZs0ag54lKTMQGRmp/iIKtLflLaAUberjjz9Wf01LMFCuXDlVgtGgtIjGHfa2LrUHWq3Czz//bHdr4Bs3bqgGLYg6TUuflSpVUlkM7XOa6tGjh9ljfC6UgrR9aI933nlHdu/erUo7aKyEv3jOGpT+PD09jaUTvBda2GL/oQGNvbAerYT2LGiRi1ImSqbIZKBkg+xAUmE/otSFrI8GjYo++ugj1dgIpRRTaDyGY+RZtH2O/WH5fni9NqHhqCmUNJBdMd0e/Pv27duqIaKrIYOE7Aga0aFUhL+2vm8wLe3cu3dPlT5xnNnzfePYRyapRYsWVktnyEqZQknL9Dm8D46zv//+2/gcfh+4VuGvvZD9wPeAEnThwoUlOjpakgLZBewrNEpELwNXQ4kZvy8cc6bHArYf+17z448/qswEMimWtP2HZfBva41nLfe7IyzPOZbHCBod49hFI0vQjhN7jwUcn/iNm2YH8DvAOrWsGzJ7OAaQPU2M1lPKWsNYvIfpMrbgOlS+fHnp1auXyqCiUeDTp09VQ1lskwaNC//44w+VjTl79qzKBKDhO87rkNy939K6JAUD6JYBiaVvTOFEgR+QaYtrwAkfF2XTEwngZGAJKR/TH5uzkAJDugvVF2jljbTZqlWrEg0MtO201uoUKTEceJYnMcvPgs8BjnwWpPJwwK9cuVL9AGvUqJFgX2qw/ahCee6559QPDCckXOBwQcNFwl4FCxYUHx8fu5dH90YESAiWkFpEV72kwn7G9mtBjek+1uabwonfHlrwioDCFI4DpFExIbCx9N1336kqAqRIUYWFCScqpPSTo6oA3xdap6M6CCc3XGxRbWYLggWc2LFN+A7w+jlz5tj1fd+6dUsFSegJZA9XHM/WIO2OaikUGNBrA+l10xQzAmDTydqJG789pOZxXkKQbxn0WUJq2HK9WlWXLTgWkL5GkK0dC6iiwbqw3Rqkt3GeQJWNLVgG1Wi2qrWSytrvAb1lUE2Bcx0CAxwj2nLacWLvsYBzNgIGHJ8a/A5wznjllVcc2lYtSLHWnVfrKWUtta/BRR+/FVQj4nhBDx5UX6E6F/sXVYymQRJ6K2C7ETxUrFhRLaMFjVmecby4uyQHAziIHa1jsTfa9fLysvq8ad2Wo+9h+SPHAbZ371510KBODBdLBAgo4T/rhOAIZz6LBhd1lLiXLFmi6mETKyWinhAnVNT/48SFiB0XORz8jvSHTuwHaKuLGEplgFJ0SrJ3W9HOAiyPW+3iiwn91C2/J9Tf40KDjBWCFG1CGxFcdCyDC1fAd4zSJvpP4yKpZbIs7du3T7V1QSCAEhFK1/i+8XpHjrGUPJ6fBe0xcIE1DbTwvZhOCIxN4WKM3wh+x/hO7Alu0NbHcr2hoaE2l8fYHkeOHFFdp02PA60baHIEhvaez571e0BpHl02cUFEgIk2Peh6CUkZJwElamRqsQ8RfK1fv15lSCwD+GdBIITzm1Y6N6U9l1j3UpzD8XvGb8AUvhcUHizbgGFMmrCwMPW7wbGC71P7/KVKlRI9S/I4A4jAMYYA+vqjwVNikHbFDsePSSvdAb4U9Am1TMs6AyUVrNOSZWkScOCikRImNLbDhRTjFvz6669W+w1r23nhwgWrg5+gFI4SZHLAyX3hwoVqm201JIM1a9aoUpZlP3nsE9MGVc6kIS3hQokqBVws0aB04sSJKkJHBiMpsJ/xQ8UxY3pywT7W5icFLqq4mOGkjYaJ9tD696MKxPTY1UrDSJsjtZqURomJwf5D1Qsaklle+Ewh1YxAAEGfaaoVjSotWfvOEQghuE9rjadQ8jctLSLAMYXgVoPjBBennTt3quweGsvao3LlygnWi2ylLThuUF2FxpeWQRECBGTE0IAN2RMENBiv4smTJzbHKcEy+N5QareVHdAyL5bnNGvnM1twnGLfINuCRtwanI+Teixg4B4sj32CBnxoXJiUAcPw+0YJ3dogUdh/yMYlVh2Na4it4Aj7HpkDa/vUdBwPFAgLFSpkLCzoVZJ7EyC1ggsf0uzaF2IK6Ret5TfS3GDZ4h8XYMCIYa6CHxjSXriYmEaYli2b8QO0pA2+Y2sEOpQcsAxK6KY/Tvx4EGlrnzM54AI/duxYlQpL7ISFk5RlKQ3pS4zwZUoLWqwFTo4aMmSIOgliv+A7RfocvQts7cdnwX5Eytb0IogfNVpBI5Vn78neEk7SXbp0USVuW62cLfedVkWAXhlI1ZtOaKmNEkhylAjxOZHqR50rUrKJfd+4yJueDJGxsDbSID6H5feNkzHqVtEa3toJOSklfvz+ELg9q5oC36m16gW0REd2ybTeWsvcWMvgoF4exwoyI6aDPD0LLgqW69Xqqa3B94w2EsggWh4LOD5A6wWCNgWoNrR2nGn7FMvg39Z6F2nL4OKMIB4lYFP4rPbSAhfL79LyfOzIsYDqD2QCEHyhJT8u6Gg7pUFwgGPAtM7eFuw/lNBN3xMFLrSPQs8IU1gnzjUarTSPthym0A4C60CGKTE4bvDe/fr1czir4W68nbnoou4FPwyUmExHIETqCBcgrQERInBcHJBJwMlIG/EJFw8cfLa6rSUFSs24OKFkhQZnOChxUsVBY9qgCiU9/MAQiKCkiRQ3fmCIEC1HfzOFOiiUMJENQUMUlGBwkUKd1bMayzgDB+qwYcPsytjgs6GkjlI6Tqo4iSHCtvz+kHpGGhqRNy4UiPDtrX/X4AeL/YZGUFpXR5RK0YBo+PDhKkvgKJS20QARxw+GD0VwgYwHUn44gdnbcNUavB6j3OECghMILrRo34CTFtaPE6HWJgTBDEreqDqydZFAehJBL44fZ9pJWIPfzLPg+EUAhpIaskfYjlmzZqk2JaYBMaCLG0pBWB6pV3zX+M6REUMwi98l9j1+zwig8RtGiddWFYUtCLxx/OE4SKwRIapX0KUO5xCU9HEM4njF6/B7wvFjz/eJ4w+/R3QRQ/BmCucBV2TrUEpF+wBbo52ivhzHP35rOP/gfIghr1Flh3Mdgghk0LD/0ZAN3e9w3kNpGhkFlNLxHSLLgRQ25mnvhQLXhAkT1F8ESDhvoSGcvRBQoNoQv0WUlrGt+L7xO7DkyLGAz4htRyYV3SJN4TPjM+C88KzzIvYHqjBwLGNEUGRScIyifYPWyFyD7cG2oUG1dkzj94lrCdo7oM0PthfnZFSXmN7rBPsN50Ysg1ENkXXDsYb93rdvX7v3p9tytjsCRmzD6GgYmAIDN6BLFAbymTFjhtmAQuiChe5wGPQiQ4YMhsDAwEQHHXpWlzZbXQu1wYTQtQrbU7p0adVFzbJrIQYOQnegAgUKqOXwF11y8Hks38OyW8+OHTvUZ8RgPOjW1qJFC5uDDll2XdS6XWmD69jTtdAWW10L0QUTA4Zg+7CdwcHBVrsE/vzzz4Zy5cqprlLWBh2yxnQ96OKH7wvdeiy72KHLGboo4b0TY+v7RhcuDIqC7kr4ftAtyPJ7SOwYSAy6FmFd6HqHgWnw+fE+6L6J7pTaADLaoE7ffvutzXXt3r1bLTNt2jSXdS10dH9h+7SBbTAiKNZlbZAtdLXCKIo4LiwHHcKgSuhWhpH7sB50zcJALpaDDllun9aFDH8d7VqIdWMwKwwohd8Rzgv4fF27dn3m70ODz2BtQCXLQayc1adPH7U+DLpjy6hRo9Qy6Gqsdef77LPPjOc8dAlGN2HTdeBYxPGL7w3HOfZ/s2bNDCEhIcZlsB7sEwxchvPrm2++qbrS2upaaK27NAYSQrdmDESE9aC7Kkbfs3acPutYMIXzBH7nWL8pe7sWakJDQ9W+wXGA7sOvvfaa6jJoCeu0PI9h/6BrIs5lOLbx+fB6y8HHMNgTBjLCb137rWCUy8RGLNUTD/wvtQMSIiJKf5CGR3sHtEmg9E3flSRERJQkqONHV2JUF1D6x8wAERHZDQ2m0ZYHA0ShrQ26GCbW8JLSB2YGiIjIbmjMiwaiaIyI3hMMBNwDMwNEREQ6x8wAERGRzjEYICIi0rkkDzqUFmCADtx/G4PQuHJ4XSIiShmoqcb9DTAQVnKOAogbH2FQPGf5+Pi4ZzsJQzqGgSoSG3CEEydOnDiljwnn8+SCgcTEO5NLtjNfvnzGgcmeZfbs2WrANAwWhemFF14wbN682TgfAyhZrv+DDz5IMAhU8+bN1YBKGAhq4MCBCQZ5wyBPVatWVQNXlShR4pkDflmTrjMD2rC0PlV7iodXwvthE7mDq1sTjl1P5C4eREZKyWKBTg0z/iwqI/D0ofiW6yTiZf+t2ROIi5WbZ5eo9dmTHcDw9hhKGvcwQQYEwyZjKGrc5VW72RbucYJhkjUYVtv4dnFxaphm3I8Gw/xjqGWM64AhmzF0NGBYaSyDO1JiOGwMAIWhq3H/jiZNmoi90nUwoFUNIBDw8GYwQO4JY8sTubsUqer19hMPJ4IBg4dj1RiWNxnDLZRxrxzcF0ELBnDxt3XzOdwn4uzZs+qeFrhXA26UhxvW4f4XuOcDqixwfxncZwTjPmj3b8B9JKZMmeJQMMAGhEREpA+INxB0JHkSBTdFMp3suUMrSvm4ORpuWIUba2lQmsedKXGjv6FDh6qb62mCg4PVHSERCGhwgcd7njlzxrgM7rhpCsvgeUek68wAERGR3VCyd7B0b+a/1+Jum6YSuzsj7sSJiz8aMOLW5LirZ7ly5dQ83GkUd81F40ncZRQlftx6ee3atWo+buVuGgiA9hjzElsGAQPuqou7N9qDwQAREZEDQkNDzarvfH1tV1Pjlui4h0NERIQavRG3Jt+zZ48KCHCbaA0yAKjnb9CggVy6dEndZj4lsZqAiIj0wakqAo9/p//a8ZhOiQUDqNcvWbKkBAUFyfjx46Vy5coybdo0q8vWrFlT/b148aL6i7YEYWFhZstoj7V2BraWwXbZmxUABgNERKSvagJnJheMj2OrjQEyCIAMAaB6AdUM4eHhxmW2b9+uLvRaVQOWsbyFNJYxbZdgD1YTEBERJQM0CGzWrJkULlxYDay0YsUK2b17t2zdulVVBeBx8+bNJVeuXKrNQP/+/aVOnTpSqVIl9frGjRuri36HDh1k4sSJqn3AsGHDpFevXsZsBLoUzpw5UwYPHixdunSRXbt2yapVq2TTpk0ObSuDASIi0geTVH+SX+8AlOgxLgDGB/D391cXeQQCjRo1Uu0O0GVw6tSpqocBGiW2bdtWXew1Xl5esnHjRunZs6cq6WfOnFm1OTAdlwDdCnHhRyCB6geMbbBgwQKHuhWm+7sWorUkdrBv9X4cZ4Dc1r19E1J7E4iS9TwekMtfNbBLrjE1jNeKoL5OXSsMT2MkJmRasm5ramGbASIiIp1jNQEREelDClcTpCcMBoiISB9cNOiQO3LfT0ZERER2YWaAiIj0gdUENjEYICIifWA1gU0MBoiISB+YGbDJfcMcIiIisgszA0REpA+sJrCJwQAREemomsCZYMBD3JX7hjlERERkF2YGiIhIHzw9/p2ceb2bYjBARET6wDYDNrnvJyMiIiK7MDNARET6wHEGbGIwQERE+sBqApvc95MRERGRXZgZICIifWA1gU0MBoiISB9YTWATgwEiItIHZgZsct8wh4iIiOzCzAAREekDqwlsYjBARET6wGoCm9w3zCEiIiK7MDNAREQ64WQ1gbhv+ZnBABER6QOrCXQY5hAREZFdmBkgIiIdZQac6U3gIe6KwQAREekDuxba5L6fjIiIiOzCzAAREekDGxDaxGCAiIj0gdUENjEYICIifWBmwCb3DXOIiIjILswMEBGRPrCawCYGA0REpA+sJrDJfcMcIiIisgszA0REpAseHh5qcmIF4q4YDBARkS4wGLCN1QREREQ6x8wAERHpAwr2zhTuPcRtMRggIiJdYDWBbawmICIi0jlmBoiISBeYGbCNwQAREekCgwHbGAwQEZEuMBiwjW0GiIiIdI6ZASIi0gd2LbSJmQEiItJVNYEzkyPmzJkjlSpVkmzZsqmpVq1a8ssvvxjnP378WHr16iW5cuWSLFmySNu2bSUsLMxsHVevXpVXX31VMmXKJHnz5pVBgwbJ06dPzZbZvXu3VKtWTXx9faVkyZKyePFicRSDASIiomRQqFAhmTBhgoSEhMjRo0fllVdekVatWsmZM2fU/P79+8uGDRtk9erVsmfPHrl+/bq0adPG+Pq4uDgVCMTGxsqBAwdkyZIl6kI/YsQI4zJXrlxRy9SvX19OnDgh/fr1k27dusnWrVsd2lYPg8FgkHQqMjJS/P39xbd6P/Hw9k3tzSFKFvf2TUjtTSBK1vN4QC5/iYiIUKXn5LxW+L85TzwyZEryegxPHkrEqved2tacOXPKpEmT5I033pA8efLIihUr1L/h/PnzUrZsWQkODpYXXnhBZRFee+01FSQEBASoZebOnStDhgyRW7duiY+Pj/r3pk2b5PTp08b3aNeundy/f1+2bNli93YxM0BERLrgIU5WE4iHMbgwnWJiYp753ijl//DDDxIdHa2qC5AtePLkiTRs2NC4TJkyZaRw4cIqGAD8rVixojEQgCZNmqj31LILWMZ0Hdoy2jrsxWCAiIjIAYGBgf9mGv6bxo8fb3PZU6dOqfYAqM/v0aOHrFu3TsqVKyc3b95UJfvs2bObLY8LP+YB/poGAtp8bV5iyyBgePTokd2fib0JiIhIF1w1zkBoaKhZNQEu9LaULl1a1eWjamHNmjXSqVMn1T4grWEwQERE+uCiroXZ/usdYA+U/tHCH4KCguTIkSMybdo0eeutt1TDQNTtm2YH0JsgX7586t/4e/jwYbP1ab0NTJex7IGAx9i+jBkz2v3RWE1ARESUQuLj41UbAwQGGTJkkJ07dxrnXbhwQXUlRJsCwF9UM4SHhxuX2b59u7rQo6pBW8Z0Hdoy2jrsxcwAERHpg5PVBAYHXzt06FBp1qyZahT44MED1XMAYwKg2x/aGnTt2lUGDBigehjgAt+nTx91EUdPAmjcuLG66Hfo0EEmTpyo2gcMGzZMjU2gVU2gHcLMmTNl8ODB0qVLF9m1a5esWrVK9TBwBIMBIiLSBWfbDHg4+FqU6Dt27Cg3btxQF38MQIRAoFGjRmr+lClTxNPTUw02hGwBegHMnj3b+HovLy/ZuHGj9OzZUwUJmTNnVm0OxowZY1ymWLFi6sKPMQtQ/YCxDRYsWKDW5dBn4zgDRGkbxxkgd5aS4wzkar9IPH2SPs5AfOxDubO8c7Jua2phmwEiIiKdYzUBERHpA29UZBODASIi0oWUbjOQnrCagIiISOeYGSAiIl1gZsA2BgNERKQLDAZsYzUBERGRzjEzQEREusDMgG0MBoiISB/YtdAmVhMQERHpHDMDRESkC6wmsI3BABER6QKDAdsYDBARkS4wGLCNbQaIiIh0jpkBIiLSB/YmsInBABER6QKrCWxjNQEREZHOMTOgM11a15QurV+QwHw51OPzV8Jk0uKdsuPQHwmWXT2pszR8obS0/3SpbN53Vj1XoUR+6fduXXmhYlHJmT2zXL1xTxb9fEi+WbPf7LXdXn9BurV5UQrnzyHXwu7L10t/lZVbj6XQpyT6f9+u2ScLf9wnoTfuqsdliueTQV2bSaOXyqvHYbcjZcT0dbL70HmJehgjJYvklY+7NJGWr1Q1ruP386EyasZPcuzsVfHy8pCW9avIuP5tJUsm31T7XOQ4ZgbSeGZg1qxZUrRoUfHz85OaNWvK4cOHU3uT3Nb18EgZPXeL1O82Q17pPlP2Hbsky8d3lDJF85ot1/PNl8VgMCR4feXSBeXWvWh5f9xKqdVhikxetktGfNBEurepZRZwDP+gqXy5aIdaZsLC7TJpQCtp+mLZFPmMRKYK5M0uI3u3kl+XDpZdSwZJ7eqlpP3AeXLu0g01v+eopXLx73BZMfkD2f/9p9KifhXpPHShnLwQqubfuHVfWveaIcUC88iORQNlzbRecu7yTek1elkqfzJylAf+83BiEgYDyWblypUyYMAAGTlypBw7dkwqV64sTZo0kfDw8NTeNLe05cA52X7wgly+dkcuhd6WcfO3SfSjWKlevrBxmQol80uvt2pL7wlrErx++eajMnT6Bjlw4or8feOurNp2QlZsDpHX6lQwLvNW42qyZP0hWbfrpFpm7c6TsmT9Yenbvm6KfU4iTbM6FaXxS+WlROG8UrJIgAz/sKVkzuQrR09fUfMPn7ws3d+qK0Hli0rRQrllYNem4p81o5w4928wsHXfacng7SVfDX5TnisaINXKF5HJQ9+S9btOyOXQW6n86YjcJBiYPHmydO/eXTp37izlypWTuXPnSqZMmWThwoWpvWluz9PTQ9o0qCSZ/HzkyJmr6rmMvhlk/sh2MmjKzxJ+N8qu9WTL4if3Hjw0Pvbx8ZLHMU/Nlnkc80SqlS0k3l6pfsiRjsXFxcuP247Kw0exUqNiMfXc85WKy7rtIXIvIlri4/+dHxPzVF4Oek7Nj33yVAUDnp7/f+xm9PVRfw+euJRKn4SSwqmsgIdzVQxpXaq2GYiNjZWQkBAZOnSo8Tn84Bo2bCjBwcGpuWlurVzxANk650Px8/FWWYEOny2TC3/9m4n5os9rcvj0Vfnlt3/bCDzL8xUKy+uvVJK3Bi82Prfr8J/SoUUN2bTvrPz+xz9SpXRB6fBaDfHJ4C25smeWsDsPku2zEVlz5uI/0qTL1/I49qlkzugryyZ1lzLF86t5i8Z3kS6fLpTiDYeoYDWjn4+aXzwwj5pfu3pp+WzKWpm+bIf0aFdPBRKjZ/6s5t28HZGqn4scxK6FaTMYuH37tsTFxUlAQIDZ83h8/vz5BMvHxMSoSRMZGZki2+lu/rx6W+p0mS7ZMvtJq/oVZPZn/5PX+syT4gVzSe1qJaRu1+l2radssQDV3uDLRTvl1yN/Gp9Hg8S8ObPK9m8+VL+d8HtR8sOWEOnbvp7Exydsh0CU3J4rEiB7lw+VyKhH8vPO4/LhqGWy8Zu+KiD4fO5GiXjwSH6a1Uc1it2856RqM7B5fj8pX7KglC2RX2aP6iDDpqyVMbPWi5enp7z/Vl11jJtmC4jSs3TVm2D8+PEyevTo1N6MdO/J0zi58s8d9W+U3KuWKSQ93nhJHsU8kWIFc8pfm0eaLb907LsSfPIvafHRPONzpYvmlZ+mdlNtAb5eustseZS++kxYI/0nrZW8ObPIzTsP5L2Wz0tk9GO5fT86hT4l0f9DVkor6VcpW1iOn70qc3/YLX07NpT5q/bKgR8+Uxd9qFiqkAQfvyQLVu+VKUPfVs/9r2kNNYXfiZRMGX0F2eLZK3ZJ0YK5UvVzkWPYmyCNBgO5c+cWLy8vCQsLM3sej/Ply5dgeVQnoLGhaWYgMDAwRbbVnXl6eIqPj7eMX7hdlm08YjbvwNL+8umMjarhoQY9D36e1l1+2HJMNUC05WlcvFy/9W/2pk2DyrLtwHmrPRSIUlq8wSCxsU/l4eNYY/sZU+g+aLCSxcqbK5v6+936YPHzySD1a5ZJoS0mV2AwkEaDAR8fHwkKCpKdO3dK69at1XNowIPHvXv3TrC8r6+vmijp0A1wx8E/JDTsvmTN5CNvNKoiL1ctJm0/XqgaDFprNHgt/L4aT0CrGkAgsOvwHzJr5T5V8oe4eIPc+a/UXyIwtwSVLSRHz4ZK9qwZVc8EvK7n56tT+NMSiarfb/hieTW2xoOHj2XNlqPyW8if8uOMD6VU0XwqY9B//Pcytu/rktM/s2zafVJ+PXRBfpjSw7iOeav2SM1KxSVzRh/59dB5GTn9J9Vd0T9rplT9bOQYXMuduZ57uG8skPrVBCjpd+rUSapXry7PP/+8TJ06VaKjo1XvAnK93NmzyJzP3pSAXFlV2v7MpRsqENh99KJdr29Zr6LkyZFF3mpSTU0aBAuV3/xS/dvL00N6vVVHShbOLU+fxsu+45ekSc85Enrz34CCKCXdvhelxhLA4ELo+YJ2AAgE6tf8d9yLVVN7qoDh7QHfSPTDGDWeANoIoDui5tiZv2XCvE0S/TBWdS+c/Onb0q7586n4qYhcy8OQBvK2M2fOlEmTJsnNmzelSpUqMn36dDX40LOgmsDf3198q/cTD29mDMg93ds3IbU3gSjZ4DwekMtfIiIiJFu2bMn2HrhWFO+zRjx9Myd5PfEx0XJ5xhvJuq26zQwAqgSsVQsQERG5jJPVBOLG1QTsF0NERKRzaSIzQERElNzYm8A2BgNERKQL7E1gG6sJiIiIdI6ZASIi0gUMLmU5wJQjDE68Nq1jMEBERLrAagLbWE1ARESkc8wMEBGRLrA3gW0MBoiISBdYTWAbgwEiItIFZgZsY5sBIiIinWNmgIiIdIGZAdsYDBARkS6wzYBtrCYgIiLSOWYGiIhIFzzEyWoCcd/UAIMBIiLSBVYT2MZqAiIiIp1jZoCIiHSBvQlsY2aAiIh0VU3gzOSI8ePHS40aNSRr1qySN29ead26tVy4cMFsmXr16hmDFG3q0aOH2TJXr16VV199VTJlyqTWM2jQIHn69KnZMrt375Zq1aqJr6+vlCxZUhYvXuzQtjIYICIiSgZ79uyRXr16ycGDB2X79u3y5MkTady4sURHR5st1717d7lx44ZxmjhxonFeXFycCgRiY2PlwIEDsmTJEnWhHzFihHGZK1euqGXq168vJ06ckH79+km3bt1k69atdm8rqwmIiEgXUrqaYMuWLWaPcRFHyT4kJETq1KljfB4l/nz58lldx7Zt2+Ts2bOyY8cOCQgIkCpVqsjYsWNlyJAhMmrUKPHx8ZG5c+dKsWLF5Ouvv1avKVu2rPz2228yZcoUadKkiV3byswAERHpQkpXE1iKiIhQf3PmzGn2/PLlyyV37txSoUIFGTp0qDx8+NA4Lzg4WCpWrKgCAQ0u8JGRkXLmzBnjMg0bNjRbJ5bB8/ZiZoCIiHTBVZmByMhIs+dRT48pMfHx8Sp9/9JLL6mLvuadd96RIkWKSIECBeTkyZOqxI92BWvXrlXzb968aRYIgPYY8xJbBtv56NEjyZgx4zM/G4MBIiIiBwQGBpo9HjlypErZJwZtB06fPq3S96bef/9947+RAcifP780aNBALl26JCVKlJCUwmCAiIj0wdlUv8e/f0JDQyVbtmzGp5+VFejdu7ds3LhR9u7dK4UKFUp02Zo1a6q/Fy9eVMEA2hIcPnzYbJmwsDD1V2tngL/ac6bLYBvtyQoA2wwQEZEuWHbhS8oEuMiaTraCAYPBoAKBdevWya5du1Qjv2dBbwBAhgBq1aolp06dkvDwcOMy6JmA9y1XrpxxmZ07d5qtB8vgeXsxGCAiIkoGqBr47rvvZMWKFWqsAdTtY0I9PqAqAD0D0Lvgr7/+kvXr10vHjh1VT4NKlSqpZdAVERf9Dh06yO+//666Cw4bNkytWwtCMC7B5cuXZfDgwXL+/HmZPXu2rFq1Svr372/3tjIYICIiXUjp3gRz5sxRPQgwsBBK+tq0cuVKNR/dAtFlEBf8MmXKyMcffyxt27aVDRs2GNfh5eWlqhjwFyX9d999VwUMY8aMMS6DjMOmTZtUNqBy5cqqi+GCBQvs7lYIbDNARES6kNLjDBgMhmc2RMTARM+C3gabN29OdBkEHMePH5ekYmaAiIhI55gZICIiXeAtjG1jMEBERLrAuxbaxmoCIiIinWNmgIiIdIGZAdsYDBARkS6wzYBtDAaIiEgXmBmwjW0GiIiIdI6ZASIi0gVWE9jGYICIiHSB1QS2sZqAiIhI55gZICIiXUC53qlqAnFfDAaIiEgXPD081OTM690VqwmIiIh0jpkBIiLSBfYmsI3BABER6QJ7E9jGYICIiHTB0+PfyZnXuyu2GSAiItI5ZgaIiEgfVJsB9i20hsEAERHpAhsQ2sZqAiIiIp1jZoCIiHTB47//nHm9u2IwQEREusDeBLaxmoCIiEjnmBkgIiJd4KBDTgYD69evF3u1bNnS7mWJiIhSCnsTOBkMtG7d2u6oKS4uzq5liYiIKB0FA/Hx8cm/JURERMmItzBOpjYDjx8/Fj8/P2dWQURElCJYTeDC3gSoBhg7dqwULFhQsmTJIpcvX1bPDx8+XL799ltHV0dERJSiDQidmdyVw8HA559/LosXL5aJEyeKj4+P8fkKFSrIggULXL19RERElNaCgaVLl8q8efOkffv24uXlZXy+cuXKcv78eVdvHxERkUurCZyZ3JXDbQb++ecfKVmypNVGhk+ePHHVdhEREbkUGxC6MDNQrlw52bdvX4Ln16xZI1WrVnV0dURERJTeMgMjRoyQTp06qQwBsgFr166VCxcuqOqDjRs3Js9WEhEROQnlemfK9h7ivhzODLRq1Uo2bNggO3bskMyZM6vg4Ny5c+q5Ro0aJc9WEhEROYm9CVw8zkDt2rVl+/btSXkpERERucugQ0ePHlUZAa0dQVBQkCu3i4iIyKV4C2MXBgPXrl2Tt99+W/bv3y/Zs2dXz92/f19efPFF+eGHH6RQoUKOrpKIiCjZ8a6FLmwz0K1bN9WFEFmBu3fvqgn/RmNCzCMiIiI3zwzs2bNHDhw4IKVLlzY+h3/PmDFDtSUgIiJKq9y4cJ+ywUBgYKDVwYVwz4ICBQo4tzVERETJhNUELqwmmDRpkvTp00c1INTg33379pWvvvrK0dURERGlaANCZyZdZwZy5MhhFhFFR0dLzZo1xdv735c/ffpU/btLly7SunXr5NtaIiIiSp1gYOrUqa5/ZyIiohTEagIngwEMP0xERJSecTjiZBh0CB4/fiyxsbFmz2XLls2ZVRIREVFaDwbQXmDIkCGyatUquXPnjtVeBURERGkNb2Hswt4EgwcPll27dsmcOXPE19dXFixYIKNHj1bdCnHnQiIiorQI13JnJ0eMHz9eatSoIVmzZpW8efOqBva4y69lhr1Xr16SK1cuyZIli7Rt21bCwsLMlrl69aq8+uqrkilTJrWeQYMGqYb7pnbv3i3VqlVT1+WSJUvK4sWLkzcYwN0JZ8+erTYYPQgw0NCwYcPkiy++kOXLlzu6OiIiIre0Z88edaE/ePCgurkfxuhp3LixyrBr+vfvr66rq1evVstfv35d2rRpY5ZtRyCAKnkM+LdkyRJ1occdgzVXrlxRy9SvX19OnDgh/fr1UyMCb9261e5t9TAYDAZHPhwil7Nnz0rhwoXVfQjWrl0rzz//vNqYihUrSlRUlKSUyMhI8ff3F9/q/cTD2zfF3pcoJd3bNyG1N4EoWc/jAbn8JSIiItnanGnXik6LD4pPpixJXk/swyhZ8t4LSd7WW7duqZI9Lvp16tRR68mTJ4+sWLFC3njjDbXM+fPnpWzZshIcHCwvvPCC/PLLL/Laa6+pICEgIEAtM3fuXFVdj/X5+Piof2/atElOnz5tfK927dqp+wZt2bIleTIDxYsXVxd+KFOmjGo7AIhstBsXERERuWs1QWRkpNkUExNj1/vj4g85c+ZUf0NCQlS2oGHDhsZlcF1FYRvBAOAvCtpaIABNmjRR73vmzBnjMqbr0JbR1pEswUDnzp3l999/V//+5JNPZNasWeLn56dSHajHICIicmeBgYEq06BNaBvwLLiZH9L3L730klSoUEE9d/PmTVWytyxI48KPedoypoGANl+bl9gyCBgePXqUPL0JcNHXIBJBSgPRDRosVKpUydHVERERpaveBKGhoWbVBGi09yxoO4A0/m+//SZuN84AFClSRE1ERERpWVJ6BJjSXotAwJE2A71795aNGzfK3r17VVs7Tb58+VTDQNTtm2YH0JsA87RlDh8+bLY+rbeB6TKWPRDwGNuYMWNG1wUD06dPF3t99NFHdi9LRETkrsMRGwwGdWO/devWqa5/xYoVM5sfFBQkGTJkkJ07d6oeeoCuh+hKWKtWLfUYfz///HMJDw9XjQ8BPRNwoS9Xrpxxmc2bN5utG8to63BZMDBlyhS7dxSDASIiIlFVA+gp8PPPP6uxBrQ6frQzQIkdf7t27SoDBgxQjQpxgUfwgIs4ehIAuiLiot+hQweZOHGiWge682PdWvVEjx49ZObMmWocINwwEGMBoXE/ehi4NBjQeg+kVX9uHMFhkMlt5ajRO7U3gSjZGOLMh7RPTp5JaTVvwtHXYnA+qFevntnzixYtkvfee89Y2Pb09FSZAfRKQC8AjOWj8fLyUlUMPXv2VEFC5syZ1f2CxowZY1wGGQdc+NGmb9q0aaoqAgMCYl0p1maAiIgoPUiNaoJnQW889MrDZAva5VlWA1hCwHH8+HFJKmeCJCIiInIDzAwQEZEuoGDv6YLeBO6IwQAREemCp5PBgKcbBwOsJiAiItK5JAUD+/btk3fffVe1bPznn3/Uc8uWLUuzIysRERFpDQidmdyVw8HAjz/+qLoroI8kWi5qN2jADRhwG2MiIqK0XE3gzOSuHA4Gxo0bp26fOH/+fDVykgY3Xzh27Jirt4+IiIjSWgNCDJWI+zBbwkhKGF+ZiIjIne9N4I4czgzghggXL15M8DzaCxQvXtxV20VERJQsdy10ZnJXDgcD3bt3l759+8qhQ4dUY4rr16/L8uXLZeDAgWq4RCIiorTI0wWTu3K4muCTTz6R+Ph4adCggTx8+FBVGeBmCQgGcIMFIiIicvNgANmAzz77TAYNGqSqC6KiotQdlbJkyZI8W0hEROQCbDOQDCMQ+vj4GO+lTERElNZ5inP1/p7ivtGAw8FA/fr1Ex14AfdRJiIiIjcOBqpUqWL2+MmTJ3LixAk5ffq0uscyERFRWsRqAhcGA1OmTLH6/KhRo1T7ASIiorSINyqyzWU9JXCvgoULF7pqdURERJTebmEcHBwsfn5+rlodERGRSyHN70wDQg83zgw4HAy0adPG7LHBYJAbN27I0aNHZfjw4a7cNiIiIpdhmwEXBgO4B4EpT09PKV26tIwZM0YaN27s6OqIiIgoPQUDcXFx0rlzZ6lYsaLkyJEj+baKiIjIxdiA0EUNCL28vFTpn3cnJCKi9MbDBf+5K4d7E1SoUEEuX76cPFtDRESUzJkBZyZ35XAwMG7cOHVToo0bN6qGg5GRkWYTERERuWmbATQQ/Pjjj6V58+bqccuWLc2GJUavAjxGuwIiIqK0hm0GXBAMjB49Wnr06CG//vqrvS8hIiJKM1BgTezeOs/izGvdJhhAyR/q1q2bnNtDREREablroTtHRURE5N5YTeCiYKBUqVLPDAju3r3ryCqJiIhSBEcgdFEwgHYDliMQEhERkY6CgXbt2knevHmTb2uIiIiSCW5S5MyNijzdODVgdzDA9gJERJSesc2ACwYd0noTEBERkU4zA/Hx8cm7JURERMnJyQaE4saZAYdvYUxERJQeeYqHmpx5vbtiMEBERLrAroUuvFERERERuRdmBoiISBfYm8A2BgNERKQLHGfANlYTEBER6RwzA0REpAtsQGgbgwEiItJP10JnqgnEfaMBVhMQERHpHDMDRESkC6wmsI3BABER6YKnk+lwT3Ff7vzZiIiIyA7MDBARkS54eHioyZnXuysGA0REpAu4lPOmhdaxmoCIiHQ1AqEzkyP27t0rLVq0kAIFCqiswk8//WQ2/7333jNmK7SpadOmZsvcvXtX2rdvL9myZZPs2bNL165dJSoqymyZkydPSu3atcXPz08CAwNl4sSJ4igGA0RERMkgOjpaKleuLLNmzbK5DC7+N27cME7ff/+92XwEAmfOnJHt27fLxo0bVYDx/vvvG+dHRkZK48aNpUiRIhISEiKTJk2SUaNGybx58xzaVlYTEBGRbqRkqr9Zs2ZqSoyvr6/ky5fP6rxz587Jli1b5MiRI1K9enX13IwZM6R58+by1VdfqYzD8uXLJTY2VhYuXCg+Pj5Svnx5OXHihEyePNksaHgWZgaIiEhX4ww4M2mlcdMpJiZGkmr37t2SN29eKV26tPTs2VPu3LljnBccHKyqBrRAABo2bCienp5y6NAh4zJ16tRRgYCmSZMmcuHCBbl3757d28FggIiIyAGol/f39zdO48ePl6RAFcHSpUtl586d8uWXX8qePXtUJiEuLk7Nv3nzpgoUTHl7e0vOnDnVPG2ZgIAAs2W0x9oy9mA1ARER6YKruhaGhoaqBn2mqf6kaNeunfHfFStWlEqVKkmJEiVUtqBBgwaSkpgZICIiXY1A6MwECARMp6QGA5aKFy8uuXPnlosXL6rHaEsQHh5utszTp09VDwOtnQH+hoWFmS2jPbbVFsEaBgNERERpwLVr11Sbgfz586vHtWrVkvv376teAppdu3ZJfHy81KxZ07gMehg8efLEuAx6HqANQo4cOex+bwYDRESkC5Z9+pMyOQLjAaBlPya4cuWK+vfVq1fVvEGDBsnBgwflr7/+Uu0GWrVqJSVLllQNAKFs2bKqXUH37t3l8OHDsn//fundu7eqXkBPAnjnnXdU40GMP4AuiCtXrpRp06bJgAEDHNpWthkgIiJdSOkRCI8ePSr169c3PtYu0J06dZI5c+aowYKWLFmiSv+4uGO8gLFjx5pVO6DrIAIAtCFAL4K2bdvK9OnTjfPRgHHbtm3Sq1cvCQoKUtUMI0aMcKhbITAYICIiSgb16tUTg8Fgc/7WrVufuQ70HFixYkWiy6Dh4b59+8QZDAaIiEgXeKMi2xgMEBGRLpj2CEjq690VgwEiItIFZgb0GegQERGRHZgZICIiXUjp3gTpCYMBIiLSBdObDSX19e6K1QREREQ6x8wAERHpgqd4qMmZ17srBgNERKQLrCawjdUEREREOsfMABER6YLHf/8583p3xWCAiIh0gdUEtrGagIiISOeYGSAiIl1Amt+ZHgEerCYgIiJK31hNYBuDASIi0gUGA7axzQAREZHOMTNARES6wK6FtjEYICIiXfD0+Hdy5vXuitUEREREOsfMABER6QKrCWxjMEBERLrA3gS2sZqAiIhI55gZICIiXUDB3rlqAvfFYICIiHSBvQlsYzUBERGRzjEzQGZmLN0un8/dKN3frCtj+7VRz4XfiZQxM3+WPUcuSNTDGClZOK/07dRIXqtfxfi6S1fD1TJHTl2R2CdPpVzJAjK4+6vyctBzqfhpSI+6tH1ZurStLYH5c6rH5y/flEnf/iI7DpxVjzfM7ZvguFz0428yYMIP6t85/DPLvLGdpHzJgpLTP5Pcvhclm/eclLGzN8iD6MdqmZeqPScbv+mb4L1LNx0q4XcepMCnpKRgb4I0Ggzs3btXJk2aJCEhIXLjxg1Zt26dtG7dOjU3SdeOn/1blv58QF3ITfUZ851ERD2SJRO7Sy7/zLJ2W4i8P3yxbP12oFQsXUgt02HQPClWKI+smdFL/HwzyLyVe9Rzh1YPl7y5sqXSJyI9uh5+X0bP/Fkuhd4SDw8PefvVmrL8q/el7rsTVGAAi9ftl/HfbDS+5tHjJ8Z/x8fHyy97TsrnczbKnXsPpFhgHpk0+E3JkS2zdB++2Oy9qrcdIw+iHxkf37oblSKfkZKGvQnSaDVBdHS0VK5cWWbNmpWam0H4Lh7GSK/Ry+TrT9qJf9ZMZvOOnL4iXd+oI9XKFZEiBXNL/85NxD9LRjl5IVTNv3M/Si6H3pI+HRpKuZIFpXhgXhnWs4U8ehwr5y/fSKVPRHq1Zd9p2X7grDomkbEaN2eDOr6rVyhmXAbHJkrw2qSV+CHiwSNZ+ONvcuLcVQm9eU/2HvlDvl2zT2pVLZHgvW7d/f91YDIYDCn2OSmpDQidm9xVqmYGmjVrpiZKfZ98vVoavlhO6tQoLVMWbzObV6NCMfl55zFp+FI5FQSs33lCHsc+lRerlVTzc/pnVlUHq385ojIFvhm8VYYhd44sUql0YCp9IiIRT08Pad2gmmTK6KOqsDT/a1pd3mxWQ1WBIXiYtOAXeRTz/9kBU/ly+0uL+lVk/7E/E8zbt/wT8fHxlnOXbsiX8zbLoZOXk/XzECWXdNVmICYmRk2ayMjIVN0ed/HT9mNy6sI12fLtx1bnzxv3nnwwfImUbfqpeHt5SkY/H1k0vquqFgCkYldN7yXvfbJASjYcok7ACAS+n9xTsmczzzIQpYRyJQrI1oUfi5+Pt0Q/ipEOg+bLhSv/VhGs2XpUQm/clZu3IqT8cwVkZO9WUrJIXuk4eIHZOhaMe0+a1a0kmfx85Je9p+SjcSuM88LuREj/L76X4+euiq+Pt3Ro9aJs+KavNHxvkpy8cC3FPy/Zx1M8xNOJXL+nG+cG0lUwMH78eBk9enRqb4Zb+Sfsngyb+qOsmvahquu35sv5m1WbgdXTP5Sc/lnkl70nVZuBn+d8JGVLFFCp0aFfrVYBAJ7DepavD5aOg+epACMgt3+Kfy7Stz//DpM67cdLtiwZpVWDqjJ7VAd57YNpKiBYsm6/cbmzl67LzduRsn7OR1K0YG7565/bxnmfTvlRvpz/iwoUhvdqKZ/3byMDv1yl5l38O1xNmsMnr0ixQrnlw3dekR4jl6bwpyV7OZvq9xD3la6CgaFDh8qAAQPMMgOBgUxDO+Pk+VDVWrpR56+Mz8XFxcvBE5dk4Y/7ZP/3n8nCNftk93efSJni+dX88s8VlEO/X5ZFP+6TiYPfkt9C/pDtB87Iha0TJGtmP7VMpUGBsvfIBVm1+bD06dgo1T4f6dOTp3Fy5dq/F/bfz4dK1XKFpUe7etJ//L89BkyFnP5L/S0emMcsGNDaASCwuBcRLb8sGCCTFmyRsDvWM5LHzvwtNSsnbFdAlB6kq2DA19dXTeQ6tauXkl+XDTF7rt/nK+S5IgHS690G8igmVj2H1L8pL09PiY83mLXEtky/eWIZNqiiNADHJur2ralY6t8eMWG3I2y//r/j39Y6oEKpQqr6gNIwpgbcIxgg18uS2U+l+k1lyuir+lrjeZSwkP4c/OUqGdGnleTMlllVE2DMgWWTuqvlgyoUlexZM8lH476TAZ2bqmqC79YHy9Xrd6Thi+VT6ZORXo3o1VJ2HDijegJkzeQnbzStrsYVaNtntqoKwOPt+8/I3YhoqfBcQZX+R+PAMxevq9c3erGc5MmVTXW1xbgaZYvnl9EftVbZMrQ1gB5v15O//7mjesvgeEebgTrVS0mbPjNT+dNTYjjOQBoNBqKiouTixYvGx1euXJETJ05Izpw5pXDhwqm5afSfDN5esvzrD+TzORuk46B5Ev0oVgUH04e1N17oc2XPIism95AJ32ySN/rMVAFE6WL5ZfGX3VSVAlFKQtuVOaM6SkDubBIZ9VjOXPxHBQK7D5+XggHZpd7zpaVnu/qqhwHazGzYdUK+WrjV+Hr0KujU+kX5on8b8cngLf+E3ZeNu0/IlMXbjcv4eHvLuH5tJH8ef5UZw3u07jVDfgtJ2OOAKD3wMKRix9jdu3dL/fr1EzzfqVMnWbzYfHAPa9BmwN/fX67evCvZsnFgG3JP+V5MONIdkbswxMVKzKn5EhERkWznce1asfPEVcmSNenvEfUgUhpUKZys26rLzEC9evU4SAcREaUINhmwjTcqIiIi0jk2ICQiIn1gasAmBgNERKQL7E1gG4MBIiLSBd610Da2GSAiItI5ZgaIiEgX2GTANgYDRESkD4wGbGI1ARERkc4xM0BERLrA3gS2MRggIiJdYG8C21hNQERElAz27t0rLVq0kAIFCoiHh4f89NNPZvMxHP+IESMkf/78kjFjRmnYsKH8+af5za7u3r0r7du3V/dCyJ49u3Tt2lXd5M/UyZMnpXbt2uLn5yeBgYEyceJEh7eVwQAREemq/aAzkyOio6OlcuXKMmvWLKvzcdGePn26zJ07Vw4dOiSZM2eWJk2ayOPHj43LIBA4c+aMbN++XTZu3KgCjPfff9/sJkyNGzeWIkWKSEhIiEyaNElGjRol8+bNc2hbWU1ARET6kMK9CZo1a6Yma5AVmDp1qgwbNkxatWqlnlu6dKkEBASoDEK7du3k3LlzsmXLFjly5IhUr15dLTNjxgxp3ry5fPXVVyrjsHz5comNjZWFCxeKj4+PlC9fXk6cOCGTJ082CxqehZkBIiIiB6A0bjrFxMSIo65cuSI3b95UVQMa3Ga5Zs2aEhwcrB7jL6oGtEAAsLynp6fKJGjL1KlTRwUCGmQXLly4IPfu3bN7exgMEBGRrnoTOPMfoF4eF25tGj9+vDgKgQAgE2AKj7V5+Js3b16z+d7e3pIzZ06zZaytw/Q97MFqAiIi0gVX9SYIDQ1VDfo0vr6+kt4xM0BERLrgqgaE2bJlM5uSEgzky5dP/Q0LCzN7Ho+1efgbHh5uNv/p06eqh4HpMtbWYfoe9mAwQERElMKKFSumLtY7d+40Pof2B2gLUKtWLfUYf+/fv696CWh27dol8fHxqm2Btgx6GDx58sS4DHoelC5dWnLkyGH39jAYICIifUjhvoVRUVGqZT8mrdEg/n316lU17kC/fv1k3Lhxsn79ejl16pR07NhR9RBo3bq1Wr5s2bLStGlT6d69uxw+fFj2798vvXv3Vj0NsBy88847qvEgxh9AF8SVK1fKtGnTZMCAAQ5tK9sMEBGRLqT0cMRHjx6V+vXrGx9rF+hOnTrJ4sWLZfDgwWosAnQBRAbg5ZdfVl0JMXiQBl0HEQA0aNBA9SJo27atGptAgwaM27Ztk169eklQUJDkzp1bDWTkSLdC9dkM6OyYTiGlgh1x9eZds8YcRO4k34t9U3sTiJKNIS5WYk7Nl4iIiGQ7j2vXioPnrkuWrEl/j6gHkfJC2QLJuq2phZkBIiLSBd6bwDYGA0REpAspPABhusIGhERERDrHzAAREekDUwM2MRggIiJdSOneBOkJqwmIiIh0jpkBIiLSBfYmsI3BABER6QKbDNjGYICIiPSB0YBNbDNARESkc8wMEBGRLrA3gW0MBoiISB+cbEAo7hsLsJqAiIhI75gZICIiXWD7QdsYDBARkT4wGrCJ1QREREQ6x8wAERHpAnsT2MZggIiIdIHDEdvGagIiIiKdY2aAiIh0ge0HbWMwQERE+sBowCYGA0REpAtsQGgb2wwQERHpHDMDRESkn1oCZ3oTiPtiMEBERLrAJgO2sZqAiIhI55gZICIiXeCgQ7YxGCAiIp1gRYEtrCYgIiLSOWYGiIhIF1hNYBuDASIi0gVWEtjGagIiIiKdY2aAiIh0gdUEtjEYICIiXeC9CWxjMEBERPrARgM2sc0AERGRzjEzQEREusDEgG0MBoiISBfYgNA2VhMQERHpHDMDRESkC+xNYBuDASIi0gc2GrCJ1QREREQ6x8wAERHpAhMDtjEYICIiXWBvAttYTUBERKRzzAwQEZFOONebQNy4ooDBABER6QKrCWxjNQEREVEyGDVqlHh4eJhNZcqUMc5//Pix9OrVS3LlyiVZsmSRtm3bSlhYmNk6rl69Kq+++qpkypRJ8ubNK4MGDZKnT5+6fFuZGSAiIkom5cuXlx07dhgfe3v//2W3f//+smnTJlm9erX4+/tL7969pU2bNrJ//341Py4uTgUC+fLlkwMHDsiNGzekY8eOkiFDBvniiy9cup0MBoiISBdSo5rA29tbXcwtRUREyLfffisrVqyQV155RT23aNEiKVu2rBw8eFBeeOEF2bZtm5w9e1YFEwEBAVKlShUZO3asDBkyRGUdfHx8xFVYTUBERLoajtiZ/xz1559/SoECBaR48eLSvn17lfaHkJAQefLkiTRs2NC4LKoQChcuLMHBweox/lasWFEFApomTZpIZGSknDlzRlyJmQEiIiIH4GJsytfXV02WatasKYsXL5bSpUurFP/o0aOldu3acvr0abl586Yq2WfPnt3sNbjwYx7gr2kgoM3X5rkSgwEiItIFV1UTBAYGmj0/cuRIlba31KxZM+O/K1WqpIKDIkWKyKpVqyRjxoySljAYICIiXXDVcMShoaGSLVs24/PWsgLWIAtQqlQpuXjxojRq1EhiY2Pl/v37ZtkB9CbQ2hjg7+HDh83WofU2sNYOwRlsM0BEROQABAKmk73BQFRUlFy6dEny588vQUFBqlfAzp07jfMvXLig2hTUqlVLPcbfU6dOSXh4uHGZ7du3q/csV66cuBIzA0REpA8pfKeigQMHSosWLVTVwPXr11V1gpeXl7z99tuqK2HXrl1lwIABkjNnTnWB79OnjwoA0JMAGjdurC76HTp0kIkTJ6p2AsOGDVNjE9gbgNiLwQAREelCUnsEaBx97bVr19SF/86dO5InTx55+eWXVbdB/BumTJkinp6earChmJgY1VNg9uzZxtcjcNi4caP07NlTBQmZM2eWTp06yZgxY8TVPAwGg0HScYtORFdXb941q78hcif5Xuyb2ptAlGwMcbESc2q+6nefXOdx7VrxT/h9p94jMjJSCubNnqzbmlqYGSAiIl3gvQlsYzBARES6kMJNBtIVBgNERKQPjAZsYtdCIiIinWNmgIiIdCGlexOkJwwGiIhIF9iA0E2DAa1X5IMH5jeNIHK3rldE7n58p0Qvd8sbDKX069OydB0MPHjwQP0t/1zR1N4UIiJy8nyOsQCSA+4OiLH8nytmfoOhpMiXL59an7tJ14MOxcfHqyEes2bNKh7unL9JQxAZ445dljfqIHIHPL5THi5BCAQKFCigRuNLLo8fP1Y3BnKWj4+P+Pn5ibtJ15kBHDiFChVK7c3QJe0GHUTuiMd3ykqujIApXMDd8SLuKuxaSEREpHMMBoiIiHSOwQA5BLfNxG04XX37TKK0gMc36VW6bkBIREREzmNmgIiISOcYDBAREekcgwEiIiKdYzBARESkcwwGyG6zZs2SokWLqoE7atasKYcPH07tTSJyib1790qLFi3UKHgYzfSnn35K7U0iSlEMBsguK1eulAEDBqhuV8eOHZPKlStLkyZNJDw8PLU3jchp0dHR6phGwEukR+xaSHZBJqBGjRoyc+ZM430hMIZ7nz595JNPPkntzSNyGWQG1q1bJ61bt07tTSFKMcwM0DPh5h4hISHSsGFDs/tC4HFwcHCqbhsRETmPwQA90+3btyUuLk4CAgLMnsfjmzdvptp2ERGRazAYICIi0jkGA/RMuXPnFi8vLwkLCzN7Ho/z5cuXattFRESuwWCAnsnHx0eCgoJk586dxufQgBCPa9WqlarbRkREzvN2wTpIB9CtsFOnTlK9enV5/vnnZerUqao7VufOnVN704icFhUVJRcvXjQ+vnLlipw4cUJy5swphQsXTtVtI0oJ7FpIdkO3wkmTJqlGg1WqVJHp06erLodE6d3u3bulfv36CZ5HALx48eJU2SailMRggIiISOfYZoCIiEjnGAwQERHpHIMBIiIinWMwQEREpHMMBoiIiHSOwQAREZHOMRggIiLSOQYDRE567733pHXr1sbH9erVk379+qXKwDkeHh5y//59m8tg/k8//WT3OkeNGqUGmHLGX3/9pd4XI/oRUdrEYIDc9gKNCxAm3FuhZMmSMmbMGHn69Gmyv/fatWtl7NixLruAExElN96bgNxW06ZNZdGiRRITEyObN2+WXr16SYYMGWTo0KEJlo2NjVVBgytgPHsiovSEmQFyW76+vuoWy0WKFJGePXtKw4YNZf369Wap/c8//1wKFCggpUuXVs+HhobKm2++KdmzZ1cX9VatWqk0tyYuLk7dtAnzc+XKJYMHDxbLEb0tqwkQjAwZMkQCAwPVNiFL8e2336r1auPh58iRQ2UIsF3aXSHHjx8vxYoVk4wZM0rlypVlzZo1Zu+DAKdUqVJqPtZjup32wnZhHZkyZZLixYvL8OHD5cmTJwmW++abb9T2Yznsn4iICLP5CxYskLJly4qfn5+UKVNGZs+e7fC2EFHqYTBAuoGLJjIAGtyC+cKFC7J9+3bZuHGjugg2adJEsmbNKvv27ZP9+/dLlixZVIZBe93XX3+tblyzcOFC+e233+Tu3buybt26RN+3Y8eO8v3336sbO507d05dWLFeXFx//PFHtQy248aNGzJt2jT1GIHA0qVLZe7cuXLmzBnp37+/vPvuu7Jnzx5j0NKmTRtp0aKFqovv1q2bfPLJJw7vE3xWfJ6zZ8+q954/f75MmTLFbBnczW/VqlWyYcMG2bJlixw/flw+/PBD4/zly5fLiBEjVGCFz/fFF1+ooGLJkiUObw8RpRLcqIjI3XTq1MnQqlUr9e/4+HjD9u3bDb6+voaBAwca5wcEBBhiYmKMr1m2bJmhdOnSankN5mfMmNGwdetW9Th//vyGiRMnGuc/efLEUKhQIeN7Qd26dQ19+/ZV/75w4QLSBur9rfn111/V/Hv37hmfe/z4sSFTpkyGAwcOmC3btWtXw9tvv63+PXToUEO5cuXM5g8ZMiTBuixh/rp162zOnzRpkiEoKMj4eOTIkQYvLy/DtWvXjM/98ssvBk9PT8ONGzfU4xIlShhWrFhhtp6xY8caatWqpf595coV9b7Hjx+3+b5ElLrYZoDcFkr7KIGjxI+0+zvvvKNax2sqVqxo1k7g999/V6VglJZNPX78WC5duqRS4yi9m9622dvbW6pXr56gqkCDUruXl5fUrVvX7u3GNjx8+FAaNWpk9jyyE1WrVlX/Rgnc8vbRtWrVEketXLlSZSzw+aKiolQDy2zZspktU7hwYSlYsKDZ+2B/IpuBfYXXdu3aVbp3725cBuvx9/d3eHuIKHUwGCC3hXr0OXPmqAs+2gXgwm0qc+bMZo9xMQwKClJpb0t58uRJctWEo7AdsGnTJrOLMKDNgasEBwdL+/btZfTo0ap6BBfvH374QVWFOLqtqF6wDE4QBBFR+sBggNwWLvZorGevatWqqZJy3rx5E5SONfnz55dDhw5JnTp1jCXgkJAQ9VprkH1AKRp1/WjAaEnLTKBhoqZcuXLqon/16lWbGQU01tMaQ2oOHjwojjhw4IBqXPnZZ58Zn/v7778TLIftuH79ugqotPfx9PRUjS4DAgLU85cvX1aBBRGlT2xASPQfXMxy586tehCgAeGVK1fUOAAfffSRXLt2TS3Tt29fmTBhghq45/z586ohXWJjBBQtWlQ6deokXbp0Ua/R1okGeYCLMXoRoErj1q1bqqSN1PvAgQNVo0E0wkMa/tixYzJjxgxjo7wePXrIn3/+KYMGDVLp+hUrVqiGgI547rnn1IUe2QC8B6oLrDWGRA8BfAZUo2C/YH+gRwF6agAyC2jwiNf/8ccfcurUKdWlc/LkyQ5tDxGlHgYDRP9Bt7m9e/eqOnK01EfpG3XhaDOgZQo+/vhj6dChg7o4ou4cF+7XX3890fWiquKNN95QgQO63aFuPTo6Ws1DNQAupugJgFJ279691fMYtAgt8nGRxXagRwOqDdDVELCN6ImAAAPdDtHrAK34HdGyZUsVcOA9McogMgV4T0vIrmB/NG/eXBo3biyVKlUy6zqIngzoWogAAJkQZDMQmGjbSkRpnwdaEab2RhAREVHqYWaAiIhI5xgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0jsEAERGRzjEYICIi0jkGA0RERDrHYICIiEjnGAwQERHpHIMBIiIinWMwQEREJPr2f/FkOzoAF+5rAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_matrix(true_values, predicted_values, accuracy, \"GAT Match: \"  + match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da014330419dafa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:10:36.696771Z",
     "start_time": "2025-02-05T11:10:36.688431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9009\n",
      "Recall: 0.8787\n",
      "F1 Score: 0.8896\n",
      "AUROC: 0.8884\n",
      "Accuracy: 0.8882\n",
      "Metrics saved to /Users/jawayria/Desktop/EDISS/DIE/ADES-Reliability-Estimation/src/../models/booster/results/3-2.csv\n"
     ]
    }
   ],
   "source": [
    "generate_metrics(true_values, predicted_values, match, model_checkpoints_path, NUM_EPOCHS, LEARNING_RATE, NODE_FEATURES, DROPOUT_RATE, PATIENCE, HIDDEN_DIM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
